[
   {
      "author_association" : "MEMBER",
      "body" : "Concept ACK, will review soon",
      "created_at" : "2022-07-26T23:32:30Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196096355",
      "id" : 1196096355,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HSvtj",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196096355/reactions"
      },
      "updated_at" : "2022-07-26T23:32:30Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196096355",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#25725](https://github.com/bitcoin/bitcoin/pull/25725) (consensus: Remove mainnet checkpoints by sdaftuar)\n* [#25673](https://github.com/bitcoin/bitcoin/pull/25673) (refactor: make member functions const when applicable by aureleoules)\n* [#24571](https://github.com/bitcoin/bitcoin/pull/24571) (p2p: Prevent block index fingerprinting by sending additional getheaders messages by dergoegge)\n* [#23352](https://github.com/bitcoin/bitcoin/pull/23352) (test: Extend stale_tip_peer_management test by MarcoFalke)\n* [#18933](https://github.com/bitcoin/bitcoin/pull/18933) (rpc: Add submit option to generateblock by MarcoFalke)\n* [#17860](https://github.com/bitcoin/bitcoin/pull/17860) (fuzz: BIP 42, BIP 30, CVE-2018-17144 by MarcoFalke)\n* [#16981](https://github.com/bitcoin/bitcoin/pull/16981) (Improve runtime performance of --reindex by LarryRuane)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.",
      "created_at" : "2022-07-27T06:03:31Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196300260",
      "id" : 1196300260,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HThfk",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196300260/reactions"
      },
      "updated_at" : "2022-08-04T09:48:10Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196300260",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/39886733?v=4",
         "events_url" : "https://api.github.com/users/DrahtBot/events{/privacy}",
         "followers_url" : "https://api.github.com/users/DrahtBot/followers",
         "following_url" : "https://api.github.com/users/DrahtBot/following{/other_user}",
         "gists_url" : "https://api.github.com/users/DrahtBot/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/DrahtBot",
         "id" : 39886733,
         "login" : "DrahtBot",
         "node_id" : "MDQ6VXNlcjM5ODg2NzMz",
         "organizations_url" : "https://api.github.com/users/DrahtBot/orgs",
         "received_events_url" : "https://api.github.com/users/DrahtBot/received_events",
         "repos_url" : "https://api.github.com/users/DrahtBot/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/DrahtBot/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/DrahtBot/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/DrahtBot"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "It's worth pointing out that initial headers sync will be slowed down by this PR, not just because we will download headers twice before storing, but also because the additional latency to make progress on syncing with our initial headers-sync-peer will mean that we're more likely to receive a block announcement while waiting for headers sync to finish, which in turn will trigger a headers sync with all our peers that announce the block. (And our starting point for those syncs will be further behind, because we don't make progress on adding headers to our block index until phase 2.)\r\n\r\nI opened #25720 as a mitigation for this effect; many strategies are possible and I think they are orthogonal to the change proposed here, so I'd prefer to leave the discussion of this particular issue to that PR.",
      "created_at" : "2022-07-27T15:59:13Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196948065",
      "id" : 1196948065,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HV_ph",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196948065/reactions"
      },
      "updated_at" : "2022-07-27T15:59:13Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196948065",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "This seems to be based on the assumption that the DoS is attacking disk space, but bandwidth tends to be more limited than space, and it makes that worse even in the best scenario...?",
      "created_at" : "2022-07-27T19:53:09Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197297765",
      "id" : 1197297765,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXVBl",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197297765/reactions"
      },
      "updated_at" : "2022-07-27T19:53:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197297765",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/1095675?v=4",
         "events_url" : "https://api.github.com/users/luke-jr/events{/privacy}",
         "followers_url" : "https://api.github.com/users/luke-jr/followers",
         "following_url" : "https://api.github.com/users/luke-jr/following{/other_user}",
         "gists_url" : "https://api.github.com/users/luke-jr/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/luke-jr",
         "id" : 1095675,
         "login" : "luke-jr",
         "node_id" : "MDQ6VXNlcjEwOTU2NzU=",
         "organizations_url" : "https://api.github.com/users/luke-jr/orgs",
         "received_events_url" : "https://api.github.com/users/luke-jr/received_events",
         "repos_url" : "https://api.github.com/users/luke-jr/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/luke-jr/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/luke-jr/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/luke-jr"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@luke-jr The DoS concern is primarily about memory usage: filling mapBlockIndex and other data structures with low-difficulty headers before a checkpoint is reached.\r\n\r\nBandwidth is a concern for sure, but:\r\n* There are many more effective ways to perform bandwidth DoS (like spamming INV messages, ADDR messages, PING messages, continuously requesting non-existing transactions or blocks, ...).\r\n* The proper solution to bandwidth DoS is just throttling peers that waste too much of it.\r\n* In non-attack scenarios, the added bandwidth by this PR (especially when combined with #25720) is in the order of 10s of MB over a node's lifetime, which is negligible compared to the full block download.\r\n",
      "created_at" : "2022-07-27T20:24:19Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197328410",
      "id" : 1197328410,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXcga",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 1,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 1,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197328410/reactions"
      },
      "updated_at" : "2022-07-27T20:24:42Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197328410",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Is there a reason to not just prune the block index under some conditions?",
      "created_at" : "2022-07-27T20:33:17Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197336868",
      "id" : 1197336868,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXekk",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197336868/reactions"
      },
      "updated_at" : "2022-07-27T20:33:17Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197336868",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/1095675?v=4",
         "events_url" : "https://api.github.com/users/luke-jr/events{/privacy}",
         "followers_url" : "https://api.github.com/users/luke-jr/followers",
         "following_url" : "https://api.github.com/users/luke-jr/following{/other_user}",
         "gists_url" : "https://api.github.com/users/luke-jr/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/luke-jr",
         "id" : 1095675,
         "login" : "luke-jr",
         "node_id" : "MDQ6VXNlcjEwOTU2NzU=",
         "organizations_url" : "https://api.github.com/users/luke-jr/orgs",
         "received_events_url" : "https://api.github.com/users/luke-jr/received_events",
         "repos_url" : "https://api.github.com/users/luke-jr/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/luke-jr/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/luke-jr/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/luke-jr"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Here is the script to compute the optimal parameters used, with lots of explanation: https://gist.github.com/sipa/016ae445c132cdf65a2791534dfb7ae1 (it takes around 20s for me in `pypy3`, though over 2 minutes in `python3`).\r\n\r\nIt may make sense to include the script in the repository (as I can imagine it being re-run to tune things occasionally, but there should not be a need to do it more than every few years). It could also live on the devwiki or just linked-to in the code. Opinions?\r\n\r\n",
      "created_at" : "2022-07-27T21:14:13Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197375266",
      "id" : 1197375266,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXn8i",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197375266/reactions"
      },
      "updated_at" : "2022-07-28T02:33:26Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197375266",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@luke-jr I think that's a potentially useful but orthogonal improvement, though there is probably much less need for it after this PR.",
      "created_at" : "2022-07-27T22:29:56Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197439146",
      "id" : 1197439146,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HX3iq",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197439146/reactions"
      },
      "updated_at" : "2022-07-27T22:29:56Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197439146",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932182732"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit: please sort these alphabetically",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:55:03Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932182732",
      "id" : 932182732,
      "line" : 18,
      "node_id" : "PRRC_kwDOABII5843j_rM",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 18,
      "original_position" : 18,
      "original_start_line" : 8,
      "path" : "src/headerssync.h",
      "position" : 18,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 8,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:32Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932184020"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit: please sort these alphabetically",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:56:16Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932184020",
      "id" : 932184020,
      "line" : 5,
      "node_id" : "PRRC_kwDOABII5843j__U",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 5,
      "original_position" : 5,
      "original_start_line" : 1,
      "path" : "src/headerssync.cpp",
      "position" : 5,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 1,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932186749"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Why not do that in this PR? Maybe add a new state `FAILED` (or an extra bool on `HeadersSyncState`) that signals to `net_processing` that the peer should be disconnected? That seems simple enough and in obvious cases like this one (i.e. too many commitments or e.g. invalid PoW) the peer definitely behaved funky and should be punished.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:58:51Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932186749",
      "id" : 932186749,
      "line" : 220,
      "node_id" : "PRRC_kwDOABII5843kAp9",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 220,
      "original_position" : 220,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 220,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932235084"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Add function to validate difficulty changes\":\r\n\r\nI realize this is mostly-copied code, but can you follow the style guide here (braces when the then statement isn't on the same line)?\r\n\r\n(here and below)",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:42:00Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);\n+\n+        // Calculate the largest difficulty value possible:\n+        arith_uint256 bnNew;\n+        bnNew.SetCompact(old_nbits);\n+        bnNew *= largest_timespan;\n+        bnNew /= params.nPowTargetTimespan;\n+\n+        if (bnNew > bnPowLimit)\n+            bnNew = bnPowLimit;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932235084",
      "id" : 932235084,
      "line" : 95,
      "node_id" : "PRRC_kwDOABII5843kMdM",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 95,
      "original_position" : 25,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 25,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932238513"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Utilize anti-DoS headers download strategy\":\r\n\r\nPerhaps use doxygen comments for comments on a function/variable definition or declaration? (either `/** ... */` or `//! ...`). That way they get picked up by doxygen for generating documentation.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:45:03Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932238513",
      "id" : 932238513,
      "line" : 7,
      "node_id" : "PRRC_kwDOABII5843kNSx",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 7,
      "original_position" : 7,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 7,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932252053"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Maybe also wipe `m_chain_start_locator`?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:56:14Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932252053",
      "id" : 932252053,
      "line" : 24,
      "node_id" : "PRRC_kwDOABII5843kQmV",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 24,
      "original_position" : 24,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 24,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932256694"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nPerhaps document that this is required to guarantee that the object isn't reused with the same SaltedTxidHasher for another sync attempt.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:00:08Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932256694",
      "id" : 932256694,
      "line" : 23,
      "node_id" : "PRRC_kwDOABII5843kRu2",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 23,
      "original_position" : 23,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 23,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932259718"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nArguably, it's not exactly true that no consensus-valid chain can be longer, but it's not possible for the peer to have such a chain at the time the sync starts (it'd need a tip timestamp that is in the future at the time the sync starts).",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:02:39Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932259718",
      "id" : 932259718,
      "line" : 61,
      "node_id" : "PRRC_kwDOABII5843kSeG",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 61,
      "original_position" : 61,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 61,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932271718"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nAny reason to do this here, and not in `StartInitialDownload`? It seems a bit cleaner to set these values as soon as they're known, rather than on the fly.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:13:01Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932271718",
      "id" : 932271718,
      "line" : 168,
      "node_id" : "PRRC_kwDOABII5843kVZm",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 168,
      "original_position" : 168,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 168,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932272722"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nShould there be a restriction to not call StartInitialDownload twice on the same object?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:13:52Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932272722",
      "id" : 932272722,
      "line" : 47,
      "node_id" : "PRRC_kwDOABII5843kVpS",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 47,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 47,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932277428"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428"
         }
      },
      "author_association" : "MEMBER",
      "body" : "This only checks node 1.\r\n```suggestion\r\n        for node in self.nodes[1:]:\r\n            chaintips = node.getchaintips()\r\n            assert(len(chaintips) == 1)\r\n            assert {\r\n                'height': 0,\r\n                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\r\n                'branchlen': 0,\r\n                'status': 'active',\r\n            } in chaintips\r\n```",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:17:48Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932277428",
      "id" : 932277428,
      "line" : 39,
      "node_id" : "PRRC_kwDOABII5843kWy0",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 39,
      "original_position" : 39,
      "original_start_line" : 31,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 39,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 31,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932278011"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nPerhaps document that we rely on the caller having verified that the headers are continuous (each has the previous one's hash as their prevhash)?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:18:19Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932278011",
      "id" : 932278011,
      "line" : 179,
      "node_id" : "PRRC_kwDOABII5843kW77",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 179,
      "original_position" : 179,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 179,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281150"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think you could get rid of the `time.sleep` with `assert_debug_log`.\r\n```suggestion\r\n    with self.nodes[1].assert_debug_log(expected_msgs=[\"[net] Ignoring low-work chain\"]), self.nodes[2].assert_debug_log(expected_msgs=[\"[net] Ignoring low-work chain\"]):\r\n         self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\r\n```",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:21:05Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281150",
      "id" : 932281150,
      "line" : 30,
      "node_id" : "PRRC_kwDOABII5843kXs-",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 30,
      "original_position" : 30,
      "original_start_line" : 27,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 30,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 27,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281858"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Utilize anti-DoS headers download strategy\"\r\n\r\nWhy \"try\"? It doesn't look like the adding of a commitment can fail.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:21:42Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281858",
      "id" : 932281858,
      "line" : 216,
      "node_id" : "PRRC_kwDOABII5843kX4C",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 216,
      "original_position" : 216,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 216,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932282250"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250"
         }
      },
      "author_association" : "MEMBER",
      "body" : "node 0 and node 2 are not connected in this test but it looks like that is an assumption here?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:22:02Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932282250",
      "id" : 932282250,
      "line" : 29,
      "node_id" : "PRRC_kwDOABII5843kX-K",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 29,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 29,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932283353"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Why does `NODE1_BLOCKS_REQUIRED` match with the comment but `NODE2_BLOCKS_REQUIRED` doesn't?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:22:56Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932283353",
      "id" : 932283353,
      "line" : 19,
      "node_id" : "PRRC_kwDOABII5843kYPZ",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 19,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932286853"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think this `time.sleep` is not needed given the `sync_blocks` call below?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:25:13Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932286853",
      "id" : 932286853,
      "line" : 43,
      "node_id" : "PRRC_kwDOABII5843kZGF",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 43,
      "original_position" : 43,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 43,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932288256"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Could also use `assert_debug_log` like suggested above instead of the sleep.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:26:00Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)\n+        self.sync_blocks(self.nodes[0:2])\n+\n+        self.log.info(\"Verify that node2 still has no new headers\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932288256",
      "id" : 932288256,
      "line" : 47,
      "node_id" : "PRRC_kwDOABII5843kZcA",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 47,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 47,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932294356"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nJust a thought for later, but it's rather ugly to have to construct a `CBlockIndex` object just to be able to call `GetBlockProof`. I think `GetBlockProof` should work (or have a variant that works) with a `CBlockHeader` too, or even just the nBits value.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:29:34Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932294356",
      "id" : 932294356,
      "line" : 226,
      "node_id" : "PRRC_kwDOABII5843ka7U",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 226,
      "original_position" : 226,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 226,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932300194"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nIs it possible to set this `m_redownload_buffer_last_hash = m_chain_start->GetBlockHash(); m_redownload_buffer_last_height = m_chain_start->nHeight;` in `ValidateAndStoreHeadersCommitments` already when the transition to REDOWNLOAD state is made?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:33:58Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932300194",
      "id" : 932300194,
      "line" : 241,
      "node_id" : "PRRC_kwDOABII5843kcWi",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 241,
      "original_position" : 241,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 241,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932308150"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nCould there be a concern that the last or few last headers or so get reorganized during the second phase, resulting in a mismatch at the end? If so, perhaps it's possible to instead keep track of chainwork again in the second phase rather than remembering the exact hash at which the threshold was reached in the first phase?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:38:05Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932308150",
      "id" : 932308150,
      "line" : 272,
      "node_id" : "PRRC_kwDOABII5843keS2",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 272,
      "original_position" : 272,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 272,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932322801"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\n`return CBlockLocator(std::move(locator))` saves a copy.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:46:36Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has\n+    // sufficient work, then set a flag for processing all remaining headers.\n+    if (header.GetHash() == m_blockhash_with_sufficient_work) {\n+        m_process_all_remaining_headers = true;\n+    }\n+    return true;\n+}\n+\n+std::vector<CBlockHeader> HeadersSyncState::RemoveHeadersReadyForAcceptance()\n+{\n+    std::vector<CBlockHeader> ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    while (m_redownloaded_headers.size() > REDOWNLOAD_HEADERS_THRESHOLD ||\n+            (m_redownloaded_headers.size() > 0 && m_process_all_remaining_headers)) {\n+        ret.emplace_back(m_redownloaded_headers.front().GetFullHeader(m_redownload_buffer_first_prev_hash));\n+        m_redownloaded_headers.pop_front();\n+        m_redownload_buffer_first_prev_hash = ret.back().GetHash();\n+    }\n+    return ret;\n+}\n+\n+std::optional<CBlockLocator> HeadersSyncState::MakeNextHeadersRequest()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    std::vector<uint256> locator;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD && !m_last_header_received.IsNull()) {\n+        // During initial download, we continue from the last header received.\n+        locator.push_back(m_last_header_received.GetHash());\n+    }\n+\n+    if (m_download_state == State::REDOWNLOAD && !m_redownloaded_headers.empty()) {\n+        // During redownload, we will either download from the last received\n+        // header that we stored during the second download phase, or from the\n+        // fork point (m_chain_start).\n+        locator.push_back(m_redownload_buffer_last_hash);\n+    }\n+\n+    locator.insert(locator.end(), m_chain_start_locator.vHave.begin(),\n+            m_chain_start_locator.vHave.end());\n+    return CBlockLocator(locator);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932322801",
      "id" : 932322801,
      "line" : 317,
      "node_id" : "PRRC_kwDOABII5843kh3x",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 317,
      "original_position" : 317,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 317,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932330073"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nThis function really returns 3 things: an optional block locator, a vector of headers to process, and a bool processing_success. Having those spread over return values and mutable arguments is a bit ugly.\r\n\r\nHow about returning a typedef'd `std::optional<std::pair<std::optional<CBlockLocator>, std::vector<CBlockHeader>>>`, or making a simple custom struct to return the results in?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:50:56Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we\n+ * can achieve a given security target (S) while choosing H and N to minimize\n+ * memory usage in this scheme.\n+ */\n+\n+class HeadersSyncState {\n+public:\n+    HeadersSyncState(NodeId id, const Consensus::Params& consensus_params);\n+    ~HeadersSyncState() {}\n+\n+    enum class State {\n+        /** INITIAL_DOWNLOAD means the peer has not yet demonstrated their\n+         * chain has sufficient work */\n+        INITIAL_DOWNLOAD,\n+        /** REDOWNLOAD means the peer has given us a high-enough-work chain,\n+         * and now we're redownloading the headers we saw before and trying to\n+         * accept them */\n+        REDOWNLOAD,\n+        /** We're done syncing with this peer and can discard any remaining state */\n+        FINAL\n+    };\n+\n+    /** Return the current state of our download */\n+    State GetState() const { return m_download_state; }\n+\n+    /** Start headers sync (via this download-twice mechanism)\n+     * chain_start: best known fork point that the peer's headers branch from\n+     * initial_headers: first batch of headers to process\n+     * minimum_required_work: amount of chain work required to accept the chain\n+     */\n+    std::optional<CBlockLocator> StartInitialDownload(const CBlockIndex* chain_start, const\n+            std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+            minimum_required_work, CBlockLocator&& chain_start_locator);\n+\n+    /** Process a batch of headers, once a sync via this mechanism has started\n+     *\n+     * headers: headers that were received over the network for processing\n+     * full_headers_message: true if the message was at max capacity,\n+     *                       indicating more headers may be available\n+     * headers_to_process: will be filled in with any headers that the caller\n+     *                     can process and validate now (because these returned\n+     *                     headers are on a chain with sufficient work)\n+     * processing_success: set to false if an error is detected and the sync is\n+     *                     aborted; true otherwise.\n+     */\n+    std::optional<CBlockLocator> ProcessNextHeaders(const std::vector<CBlockHeader>& headers,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932330073",
      "id" : 932330073,
      "line" : 140,
      "node_id" : "PRRC_kwDOABII5843kjpZ",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 140,
      "original_position" : 140,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : 140,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "concept ACK, cool to see such an old idea actually get implemented",
      "created_at" : "2022-07-28T18:22:55Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1198490639",
      "id" : 1198490639,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585Hb4QP",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1198490639/reactions"
      },
      "updated_at" : "2022-07-28T18:22:55Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1198490639",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932560137"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this relation between `pindexLast.nBits` and `expected_nbits` be explicitly computed? Would make the test condition below abundantly clear.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:38:44Z",
      "diff_hunk" : "@@ -44,7 +48,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_lower_limit_actual)\n     pindexLast.nHeight = 68543;\n     pindexLast.nTime = 1279297671;  // Block #68543\n     pindexLast.nBits = 0x1c05a3f4;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1c0168fdU);\n+    unsigned int expected_nbits = 0x1c0168fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932560137",
      "id" : 932560137,
      "line" : 51,
      "node_id" : "PRRC_kwDOABII5843lb0J",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 51,
      "original_position" : 27,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 27,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562089"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this just be the (casted) value of pindexLast.nBits?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:41:12Z",
      "diff_hunk" : "@@ -32,7 +34,9 @@ BOOST_AUTO_TEST_CASE(get_next_work_pow_limit)\n     pindexLast.nHeight = 2015;\n     pindexLast.nTime = 1233061996;  // Block #2015\n     pindexLast.nBits = 0x1d00ffff;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1d00ffffU);\n+    unsigned int expected_nbits = 0x1d00ffffU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562089",
      "id" : 932562089,
      "line" : 37,
      "node_id" : "PRRC_kwDOABII5843lcSp",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 37,
      "original_position" : 16,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 16,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562835"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this relation between `pindexLast.nBits` and `expected_nbits` be explicitly computed? Would make the test condition below abundantly clear.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:42:06Z",
      "diff_hunk" : "@@ -56,7 +65,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_upper_limit_actual)\n     pindexLast.nHeight = 46367;\n     pindexLast.nTime = 1269211443;  // Block #46367\n     pindexLast.nBits = 0x1c387f6f;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1d00e1fdU);\n+    unsigned int expected_nbits = 0x1d00e1fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562835",
      "id" : 932562835,
      "line" : 68,
      "node_id" : "PRRC_kwDOABII5843lceT",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 68,
      "original_position" : 41,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 41,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932564292"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292"
         }
      },
      "author_association" : "MEMBER",
      "body" : "while we're here, what does `bn` actually refer to? :grimacing: \r\n\r\nwouldn't mind tossing the old naming schemes for this",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:44:03Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932564292",
      "id" : 932564292,
      "line" : 84,
      "node_id" : "PRRC_kwDOABII5843lc1E",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 84,
      "original_position" : 14,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 14,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932566102"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102"
         }
      },
      "author_association" : "MEMBER",
      "body" : "splitting hairs maybe but should this also check new_bits is at/above powLimit?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:46:19Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932566102",
      "id" : 932566102,
      "line" : 78,
      "node_id" : "PRRC_kwDOABII5843ldRW",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 78,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 8,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932604102"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102"
         }
      },
      "author_association" : "MEMBER",
      "body" : "For the purposes of what is needed for the security analysis of the overall header commitment scheme, the only requirements are that this verifies (a) that the difficulty doesn't change on non-2016-multiple blocks and (b) doesn't go up or down too quickly. Its goal is forcing the attacker to spread out their attempted PoW over many blocks, rather than just one or a few (because creating `N` blocks with each difficulty `D` is much harder than creating one block with difficulty `N*D`, if the hashpower available to the attacker is less than the expected value for an `N*D` difficulty block).\r\n\r\nNo objection to checking whatever can be checked with the provided arguments, but I think the current code just chooses to check exactly what is needed, and document it, rather than verify everything possible.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T19:37:05Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932604102",
      "id" : 932604102,
      "in_reply_to_id" : 932566102,
      "line" : 78,
      "node_id" : "PRRC_kwDOABII5843lmjG",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 78,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 8,
      "pull_request_review_id" : 1054648121,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T19:39:47Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932655838"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932655838"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Hm, will `assert_debug_log` work properly here if there might be multiple \"[net] Ignoring low-work chain\" lines in our debug.log?  (Perhaps that would work if I generated one block at a time in a loop, rather than invoke `generate` once with multiple blocks?)",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T20:46:52Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932655838",
      "id" : 932655838,
      "in_reply_to_id" : 932281150,
      "line" : 30,
      "node_id" : "PRRC_kwDOABII5843lzLe",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 30,
      "original_position" : 30,
      "original_start_line" : 27,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 30,
      "pull_request_review_id" : 1054730452,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932655838/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 27,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T20:46:52Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932655838",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932715853"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715853"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:05:26Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932715853",
      "id" : 932715853,
      "in_reply_to_id" : 932182732,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mB1N",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 17,
      "original_position" : 18,
      "original_start_line" : 8,
      "path" : "src/headerssync.h",
      "position" : null,
      "pull_request_review_id" : 1054817686,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715853/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T22:05:26Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715853",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932715978"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715978"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Thanks! Fixed.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:05:41Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932715978",
      "id" : 932715978,
      "in_reply_to_id" : 932277428,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mB3K",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 39,
      "original_position" : 39,
      "original_start_line" : 31,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1054817858,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715978/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T22:05:41Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932715978",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932716716"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716716"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Oops, looks like I was off by one a couple of times when I worked on this, and didn't square this away.  Fixed now.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:07:06Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932716716",
      "id" : 932716716,
      "in_reply_to_id" : 932283353,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCCs",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1054818809,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716716/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:07:06Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716716",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932716792"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716792"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Fixed",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:07:15Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932716792",
      "id" : 932716792,
      "in_reply_to_id" : 932286853,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCD4",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 43,
      "original_position" : 43,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1054818916,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716792/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:07:15Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932716792",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717300"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717300"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Fixed the braces. Should I also fix all the variable names? (Saw @instagibbs' comment along those lines just now, so if you agree then I'll modernize the whole thing.)",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:08:21Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);\n+\n+        // Calculate the largest difficulty value possible:\n+        arith_uint256 bnNew;\n+        bnNew.SetCompact(old_nbits);\n+        bnNew *= largest_timespan;\n+        bnNew /= params.nPowTargetTimespan;\n+\n+        if (bnNew > bnPowLimit)\n+            bnNew = bnPowLimit;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717300",
      "id" : 932717300,
      "in_reply_to_id" : 932235084,
      "line" : 95,
      "node_id" : "PRRC_kwDOABII5843mCL0",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 95,
      "original_position" : 25,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 25,
      "pull_request_review_id" : 1054819633,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717300/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:08:22Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717300",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717391"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717391"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think I fixed all these now.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:08:33Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717391",
      "id" : 932717391,
      "in_reply_to_id" : 932238513,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCNP",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 7,
      "original_position" : 7,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054819771,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717391/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:08:34Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717391",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717474"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717474"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:08:41Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717474",
      "id" : 932717474,
      "in_reply_to_id" : 932252053,
      "line" : 26,
      "node_id" : "PRRC_kwDOABII5843mCOi",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 26,
      "original_position" : 24,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 26,
      "pull_request_review_id" : 1054819844,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717474/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:08:41Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717474",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717538"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717538"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:08:46Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717538",
      "id" : 932717538,
      "in_reply_to_id" : 932256694,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCPi",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 23,
      "original_position" : 23,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054819939,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717538/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:08:47Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717538",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717675"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717675"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Reworked the comment to try to make that clearer, let me know if it looks better now...",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:09:04Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717675",
      "id" : 932717675,
      "in_reply_to_id" : 932259718,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCRr",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 61,
      "original_position" : 61,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054820110,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717675/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:09:04Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717675",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717729"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717729"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:09:09Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717729",
      "id" : 932717729,
      "in_reply_to_id" : 932271718,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCSh",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 168,
      "original_position" : 168,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054820184,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717729/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:09:10Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717729",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717972"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717972"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Seems reasonable, I added a variable to do that.  Let me know if that looks good now.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:09:38Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932717972",
      "id" : 932717972,
      "in_reply_to_id" : 932272722,
      "line" : 50,
      "node_id" : "PRRC_kwDOABII5843mCWU",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 50,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 50,
      "pull_request_review_id" : 1054820479,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717972/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:09:38Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932717972",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718040"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718040"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:09:45Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718040",
      "id" : 932718040,
      "in_reply_to_id" : 932278011,
      "line" : 183,
      "node_id" : "PRRC_kwDOABII5843mCXY",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 183,
      "original_position" : 179,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 183,
      "pull_request_review_id" : 1054820569,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718040/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:09:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718040",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718129"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718129"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Fixed.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:09:54Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718129",
      "id" : 932718129,
      "in_reply_to_id" : 932281858,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCYx",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 216,
      "original_position" : 216,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054820676,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718129/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:09:54Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718129",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718308"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718308"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Yeah that's much better, thanks. Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:10:16Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718308",
      "id" : 932718308,
      "in_reply_to_id" : 932300194,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCbk",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 241,
      "original_position" : 241,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054820916,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718308/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:10:16Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718308",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718382"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718382"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:10:24Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has\n+    // sufficient work, then set a flag for processing all remaining headers.\n+    if (header.GetHash() == m_blockhash_with_sufficient_work) {\n+        m_process_all_remaining_headers = true;\n+    }\n+    return true;\n+}\n+\n+std::vector<CBlockHeader> HeadersSyncState::RemoveHeadersReadyForAcceptance()\n+{\n+    std::vector<CBlockHeader> ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    while (m_redownloaded_headers.size() > REDOWNLOAD_HEADERS_THRESHOLD ||\n+            (m_redownloaded_headers.size() > 0 && m_process_all_remaining_headers)) {\n+        ret.emplace_back(m_redownloaded_headers.front().GetFullHeader(m_redownload_buffer_first_prev_hash));\n+        m_redownloaded_headers.pop_front();\n+        m_redownload_buffer_first_prev_hash = ret.back().GetHash();\n+    }\n+    return ret;\n+}\n+\n+std::optional<CBlockLocator> HeadersSyncState::MakeNextHeadersRequest()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    std::vector<uint256> locator;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD && !m_last_header_received.IsNull()) {\n+        // During initial download, we continue from the last header received.\n+        locator.push_back(m_last_header_received.GetHash());\n+    }\n+\n+    if (m_download_state == State::REDOWNLOAD && !m_redownloaded_headers.empty()) {\n+        // During redownload, we will either download from the last received\n+        // header that we stored during the second download phase, or from the\n+        // fork point (m_chain_start).\n+        locator.push_back(m_redownload_buffer_last_hash);\n+    }\n+\n+    locator.insert(locator.end(), m_chain_start_locator.vHave.begin(),\n+            m_chain_start_locator.vHave.end());\n+    return CBlockLocator(locator);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718382",
      "id" : 932718382,
      "in_reply_to_id" : 932322801,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCcu",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 317,
      "original_position" : 317,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054821015,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718382/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:10:25Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718382",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718671"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718671"
         }
      },
      "author_association" : "MEMBER",
      "body" : "This is way better, thanks.  ",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:10:59Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we\n+ * can achieve a given security target (S) while choosing H and N to minimize\n+ * memory usage in this scheme.\n+ */\n+\n+class HeadersSyncState {\n+public:\n+    HeadersSyncState(NodeId id, const Consensus::Params& consensus_params);\n+    ~HeadersSyncState() {}\n+\n+    enum class State {\n+        /** INITIAL_DOWNLOAD means the peer has not yet demonstrated their\n+         * chain has sufficient work */\n+        INITIAL_DOWNLOAD,\n+        /** REDOWNLOAD means the peer has given us a high-enough-work chain,\n+         * and now we're redownloading the headers we saw before and trying to\n+         * accept them */\n+        REDOWNLOAD,\n+        /** We're done syncing with this peer and can discard any remaining state */\n+        FINAL\n+    };\n+\n+    /** Return the current state of our download */\n+    State GetState() const { return m_download_state; }\n+\n+    /** Start headers sync (via this download-twice mechanism)\n+     * chain_start: best known fork point that the peer's headers branch from\n+     * initial_headers: first batch of headers to process\n+     * minimum_required_work: amount of chain work required to accept the chain\n+     */\n+    std::optional<CBlockLocator> StartInitialDownload(const CBlockIndex* chain_start, const\n+            std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+            minimum_required_work, CBlockLocator&& chain_start_locator);\n+\n+    /** Process a batch of headers, once a sync via this mechanism has started\n+     *\n+     * headers: headers that were received over the network for processing\n+     * full_headers_message: true if the message was at max capacity,\n+     *                       indicating more headers may be available\n+     * headers_to_process: will be filled in with any headers that the caller\n+     *                     can process and validate now (because these returned\n+     *                     headers are on a chain with sufficient work)\n+     * processing_success: set to false if an error is detected and the sync is\n+     *                     aborted; true otherwise.\n+     */\n+    std::optional<CBlockLocator> ProcessNextHeaders(const std::vector<CBlockHeader>& headers,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932718671",
      "id" : 932718671,
      "in_reply_to_id" : 932330073,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mChP",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 140,
      "original_position" : 140,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : null,
      "pull_request_review_id" : 1054821402,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718671/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T22:10:59Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932718671",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932719744"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932719744"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-28T22:13:18Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932719744",
      "id" : 932719744,
      "in_reply_to_id" : 932184020,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843mCyA",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 4,
      "original_position" : 5,
      "original_start_line" : 1,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1054822937,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932719744/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T22:13:18Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932719744",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933048600"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933048600"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Not needed since you're not using wallet in this test",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-29T09:26:59Z",
      "diff_hunk" : "@@ -0,0 +1,67 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933048600",
      "id" : 933048600,
      "line" : 23,
      "node_id" : "PRRC_kwDOABII5843nTEY",
      "original_commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "original_line" : 23,
      "original_position" : 23,
      "original_start_line" : 22,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 23,
      "pull_request_review_id" : 1055265006,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933048600/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 22,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-29T09:54:43Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933048600",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933060182"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933060182"
         }
      },
      "author_association" : "MEMBER",
      "body" : "+1, it looks like node2 currently doesn't receive any headers because it's not connected to node0?\r\nIIRC the default is that 0-1 and 1-2 are connected. My suggestion would be to override `setup_network` with:\r\n\r\n```\r\nself.setup_nodes()\r\nself.connect_nodes(0, 1)\r\nself.connect_nodes(0, 2)\r\nself.sync_all(self.nodes[0:2])\r\n```",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-29T09:41:00Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933060182",
      "id" : 933060182,
      "in_reply_to_id" : 932282250,
      "line" : 29,
      "node_id" : "PRRC_kwDOABII5843nV5W",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 29,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 29,
      "pull_request_review_id" : 1055265006,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933060182/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-29T09:54:43Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933060182",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933068912"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933068912"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I agree with removing the `sleep()` since it's not a very reliable way to wait for things to happen in the functional tests (which are often run in parallel). Not sure about relying on `assert_debug_log`.\r\n\r\nI'd recommend `wait_until` the headers are received, for example:\r\n\r\n```suggestion\r\n        self.log.info(\"Generate blocks on the node with no required chainwork\")\r\n        node1_recv_headers = self.nodes[1].getpeerinfo()[0][\"bytesrecv_per_msg\"][\"headers\"]\r\n        node2_recv_headers = self.nodes[2].getpeerinfo()[0][\"bytesrecv_per_msg\"][\"headers\"]\r\n        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\r\n\r\n        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\r\n        self.wait_until(lambda: self.nodes[1].getpeerinfo()[0][\"bytesrecv_per_msg\"][\"headers\"] > node1_recv_headers)\r\n        self.wait_until(lambda: self.nodes[2].getpeerinfo()[0][\"bytesrecv_per_msg\"][\"headers\"] > node2_recv_headers)\r\n        for node in self.nodes[1:]:\r\n```\r\n(this is using `getpeerinfo()[0]` assuming node1 and node2 have node0 as their first peer)",
      "commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "created_at" : "2022-07-29T09:51:32Z",
      "diff_hunk" : "@@ -0,0 +1,67 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for node in self.nodes[1:]:",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933068912",
      "id" : 933068912,
      "line" : 31,
      "node_id" : "PRRC_kwDOABII5843nYBw",
      "original_commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "original_line" : 31,
      "original_position" : 31,
      "original_start_line" : 26,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 31,
      "pull_request_review_id" : 1055265006,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933068912/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 26,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-29T09:54:43Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933068912",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933198524"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933198524"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I'm not sure there's a great way to do this without essentially duplicating the code from `pow.cpp`; is that what you have in mind?  (That might be a reasonable suggestion, I'm just not sure what makes the most sense.)",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T12:35:00Z",
      "diff_hunk" : "@@ -44,7 +48,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_lower_limit_actual)\n     pindexLast.nHeight = 68543;\n     pindexLast.nTime = 1279297671;  // Block #68543\n     pindexLast.nBits = 0x1c05a3f4;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1c0168fdU);\n+    unsigned int expected_nbits = 0x1c0168fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933198524",
      "id" : 933198524,
      "in_reply_to_id" : 932560137,
      "line" : 51,
      "node_id" : "PRRC_kwDOABII5843n3q8",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 51,
      "original_position" : 27,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 27,
      "pull_request_review_id" : 1055491612,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933198524/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-29T12:35:20Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933198524",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933233479"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933233479"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Not convinced either way, maybe just comment on the relationship here?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T12:59:45Z",
      "diff_hunk" : "@@ -44,7 +48,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_lower_limit_actual)\n     pindexLast.nHeight = 68543;\n     pindexLast.nTime = 1279297671;  // Block #68543\n     pindexLast.nBits = 0x1c05a3f4;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1c0168fdU);\n+    unsigned int expected_nbits = 0x1c0168fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933233479",
      "id" : 933233479,
      "in_reply_to_id" : 932560137,
      "line" : 51,
      "node_id" : "PRRC_kwDOABII5843oANH",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 51,
      "original_position" : 27,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 27,
      "pull_request_review_id" : 1055535674,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933233479/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-29T12:59:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933233479",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933235315"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933235315"
         }
      },
      "author_association" : "MEMBER",
      "body" : "question in 5072054428fa9229a0e34b9eb4a0eed97639012d: what's the rationale for fuzzing with 128 instead of default blob size?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T13:01:32Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933235315",
      "id" : 933235315,
      "line" : 19,
      "node_id" : "PRRC_kwDOABII5843oApz",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 19,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933235315/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933235315",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933239940"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933239940"
         }
      },
      "author_association" : "MEMBER",
      "body" : "in 5072054428fa9229a0e34b9eb4a0eed97639012d:\r\n\r\nPerhaps these methods could be fuzzed too?\r\n- `clear()`\r\n- `resize()`\r\n- `max_size()`\r\n- `emplace()` (though maybe unnecessary since there's already `insert`)",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T13:05:35Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;\n+\n+//! Deterministic random vector of bools, for begin/end insertions to draw from.\n+std::vector<bool> RANDDATA;\n+\n+void InitRandData()\n+{\n+    FastRandomContext ctx(true);\n+    RANDDATA.clear();\n+    for (size_t i = 0; i < (1U << RANDDATA_BITS) + (1U << LEN_BITS); ++i) {\n+        RANDDATA.push_back(ctx.randbool());\n+    }\n+}\n+\n+} // namespace\n+\n+FUZZ_TARGET_INIT(bitdeque, InitRandData)\n+{\n+    FuzzedDataProvider provider(buffer.data(), buffer.size());\n+    FastRandomContext ctx(true);\n+\n+    size_t maxlen = (1U << provider.ConsumeIntegralInRange<size_t>(0, LEN_BITS)) - 1;\n+    size_t limitlen = 4 * maxlen;\n+\n+    std::deque<bool> deq;\n+    bitdeque_type bitdeq;\n+\n+    const auto& cdeq = deq;\n+    const auto& cbitdeq = bitdeq;\n+\n+    size_t initlen = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+    while (initlen) {\n+        bool val = ctx.randbool();\n+        deq.push_back(val);\n+        bitdeq.push_back(val);\n+        --initlen;\n+    }\n+\n+    while (provider.remaining_bytes()) {\n+        {\n+            assert(deq.size() == bitdeq.size());\n+            auto it = deq.begin();\n+            auto bitit = bitdeq.begin();\n+            auto itend = deq.end();\n+            while (it != itend) {\n+                assert(*it == *bitit);\n+                ++it;\n+                ++bitit;\n+            }\n+        }\n+\n+        CallOneOf(provider,\n+            [&] {\n+                // constructor()\n+                deq = std::deque<bool>{};\n+                bitdeq = bitdeque_type{};\n+            },\n+            [&] {\n+                // assign(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq.assign(count, val);\n+                bitdeq.assign(count, val);\n+            },\n+            [&] {\n+                // constructor(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq = std::deque<bool>(count, val);\n+                bitdeq = bitdeque_type(count, val);\n+            },\n+            [&] {\n+                // constructor(count)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                deq = std::deque<bool>(count);\n+                bitdeq = bitdeque_type(count);\n+            },\n+            [&] {\n+                // construct(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq = std::deque<bool>(rand_begin, rand_end);\n+                bitdeq = bitdeque_type(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // assign(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq.assign(rand_begin, rand_end);\n+                bitdeq.assign(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // construct(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = std::deque<bool>(ilist);\n+                bitdeq = bitdeque_type(ilist);\n+            },\n+            [&] {\n+                // assign(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq.assign(ilist);\n+                bitdeq.assign(ilist);\n+            },\n+            [&] {\n+                // operator=(const&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                const std::deque<bool> deq2(count, val);\n+                deq = deq2;\n+                const bitdeque_type bitdeq2(count, val);\n+                bitdeq = bitdeq2;\n+            },\n+            [&] {\n+                // operator=(&&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                std::deque<bool> deq2(count, val);\n+                deq = std::move(deq2);\n+                bitdeque_type bitdeq2(count, val);\n+                bitdeq = std::move(bitdeq2);\n+            },\n+            [&] {\n+                // deque swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                using std::swap;\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                swap(deq, deq2);\n+                swap(bitdeq, bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // deque.swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                deq.swap(deq2);\n+                bitdeq.swap(bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // operator=(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = ilist;\n+                bitdeq = ilist;\n+            },\n+            [&] {\n+                // iterator arithmetic\n+                auto pos1 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto pos2 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto it = deq.begin() + pos1;\n+                auto bitit = bitdeq.begin() + pos1;\n+                if ((size_t)pos1 != cdeq.size()) assert(*it == *bitit);\n+                assert(it - deq.begin() == pos1);\n+                assert(bitit - bitdeq.begin() == pos1);\n+                if (provider.ConsumeBool()) {\n+                    it += pos2 - pos1;\n+                    bitit += pos2 - pos1;\n+                } else {\n+                    it -= pos1 - pos2;\n+                    bitit -= pos1 - pos2;\n+                }\n+                if ((size_t)pos2 != cdeq.size()) assert(*it == *bitit);\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+                if (provider.ConsumeBool()) {\n+                    if ((size_t)pos2 != cdeq.size()) {\n+                        ++it;\n+                        ++bitit;\n+                    }\n+                } else {\n+                    if (pos2 != 0) {\n+                        --it;\n+                        --bitit;\n+                    }\n+                }\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+            },\n+            [&] {\n+                // begin() and end()\n+                assert(deq.end() - deq.begin() == bitdeq.end() - bitdeq.begin());\n+            },\n+            [&] {\n+                // begin() and end() (const)\n+                assert(cdeq.end() - cdeq.begin() == cbitdeq.end() - cbitdeq.begin());\n+            },\n+            [&] {\n+                // rbegin() and rend()\n+                assert(deq.rend() - deq.rbegin() == bitdeq.rend() - bitdeq.rbegin());\n+            },\n+            [&] {\n+                // rbegin() and rend() (const)\n+                assert(cdeq.rend() - cdeq.rbegin() == cbitdeq.rend() - cbitdeq.rbegin());\n+            },\n+            [&] {\n+                // cbegin() and cend()\n+                assert(cdeq.cend() - cdeq.cbegin() == cbitdeq.cend() - cbitdeq.cbegin());\n+            },\n+            [&] {\n+                // crbegin() and crend()\n+                assert(cdeq.crend() - cdeq.crbegin() == cbitdeq.crend() - cbitdeq.crbegin());\n+            },\n+            [&] {\n+                // size\n+                assert(cdeq.size() == cbitdeq.size());\n+            },\n+            [&] {\n+                // empty\n+                assert(cdeq.empty() == cbitdeq.empty());\n+            },\n+            [&] {\n+                // at (in range) and flip\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    auto& ref = deq.at(pos);\n+                    auto bitref = bitdeq.at(pos);\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // at (maybe out of range) and bit assign\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool newval = ctx.randbool();\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = deq.at(pos);\n+                    val_deq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = bitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // at (maybe out of range) (const)\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = cdeq.at(pos);\n+                    val_deq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = cbitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // operator[]\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                    if (ctx.randbool()) {\n+                        deq[pos] = !deq[pos];\n+                        bitdeq[pos].flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // operator[] const\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                }\n+            },\n+            [&] {\n+                // front()\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.front();\n+                    auto bitref = bitdeq.front();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref = !bitref;\n+                    }\n+                }\n+            },\n+            [&] {\n+                // front() const\n+                if (!cdeq.empty()) {\n+                    auto& ref = cdeq.front();\n+                    auto bitref = cbitdeq.front();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // back() and swap(bool, ref)\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.back();\n+                    auto bitref = bitdeq.back();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // back() const\n+                if (!cdeq.empty()) {\n+                    const auto& cdeq = deq;\n+                    const auto& cbitdeq = bitdeq;\n+                    auto& ref = cdeq.back();\n+                    auto bitref = cbitdeq.back();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // push_back()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // push_front()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_back()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 2);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_front()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(1, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // erase (in middle, single)\n+                if (!cdeq.empty()) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    size_t after = cdeq.size() - 1 - before;\n+                    auto it = deq.erase(cdeq.begin() + before);\n+                    auto bitit = bitdeq.erase(cbitdeq.begin() + before);\n+                    assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                    assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+                }\n+            },\n+            [&] {\n+                // erase (at front, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.begin(), cdeq.begin() + count);\n+                auto bitit = bitdeq.erase(cbitdeq.begin(), cbitdeq.begin() + count);\n+                assert(it == deq.begin());\n+                assert(bitit == bitdeq.begin());\n+            },\n+            [&] {\n+                // erase (at back, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.end() - count, cdeq.end());\n+                auto bitit = bitdeq.erase(cbitdeq.end() - count, cbitdeq.end());\n+                assert(it == deq.end());\n+                assert(bitit == bitdeq.end());\n+            },\n+            [&] {\n+                // erase (in middle, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - count);\n+                size_t after = cdeq.size() - count - before;\n+                auto it = deq.erase(cdeq.begin() + before, cdeq.end() - after);\n+                auto bitit = bitdeq.erase(cbitdeq.begin() + before, cbitdeq.end() - after);\n+                assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+            },\n+            [&] {\n+                // insert (in middle, single)\n+                if (cdeq.size() < limitlen) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (at front, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin(), rand_begin, rand_end);\n+                    assert(it == cdeq.begin());\n+                    assert(bitit == cbitdeq.begin());\n+                }\n+            },\n+            [&] {\n+                // insert (at back, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.end(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.end(), rand_begin, rand_end);\n+                    assert(it == cdeq.end() - count);\n+                    assert(bitit == cbitdeq.end() - count);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, range)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, count, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, count, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin() + before, rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, rand_begin, rand_end);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933239940",
      "id" : 933239940,
      "line" : 523,
      "node_id" : "PRRC_kwDOABII5843oByE",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 523,
      "original_position" : 523,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 523,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933239940/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933239940",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933301267"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933301267"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Fixed.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T13:56:58Z",
      "diff_hunk" : "@@ -0,0 +1,67 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933301267",
      "id" : 933301267,
      "in_reply_to_id" : 933048600,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843oQwT",
      "original_commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "original_line" : 23,
      "original_position" : 23,
      "original_start_line" : 22,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1055610302,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933301267/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-29T13:56:59Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933301267",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933302625"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933302625"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Ah, that's clever, but I think the problem is that the number of headers messages that come in after a call to `generate` is variable, based on the particular blocks that get INV'ed and the responses they generate.  \r\n\r\nI took an approach of changing the logging to include the height of the chain, and then used the `assert_debug_log` approach to check for it.  This gets rid of all the sleeps and I think ought to work?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T13:58:16Z",
      "diff_hunk" : "@@ -0,0 +1,67 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for node in self.nodes[1:]:",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933302625",
      "id" : 933302625,
      "in_reply_to_id" : 933068912,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843oRFh",
      "original_commit_id" : "ec2723b39f4a994938d2d7f14586dcde823fe37e",
      "original_line" : 31,
      "original_position" : 31,
      "original_start_line" : 26,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1055612143,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933302625/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-29T13:58:16Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933302625",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933501386"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933501386"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Maybe it's a bit more natural and concise to have a separate state for this? e,g. have states `UNSTARTED`, `INITAL_DOWNLOAD`, `REDOWNLOAD`, `FINAL`?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T17:58:38Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933501386",
      "id" : 933501386,
      "in_reply_to_id" : 932272722,
      "line" : 50,
      "node_id" : "PRRC_kwDOABII5843pBnK",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 50,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 50,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933501386/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933501386",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933507679"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933507679"
         }
      },
      "author_association" : "MEMBER",
      "body" : "There are lots of `return ret;` statements in this function now. Perhaps it's cleaner to restructure it so that there is only a single return statement at the end, and all the branches just modify the values in `ret`?\r\n\r\n",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-29T18:08:25Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+    assert(m_sync_started == false);\n+\n+    m_sync_started = true;\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return ret;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r933507679",
      "id" : 933507679,
      "line" : 106,
      "node_id" : "PRRC_kwDOABII5843pDJf",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 106,
      "original_position" : 106,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 106,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933507679/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/933507679",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934021719"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021719"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Now that I think about it, it's possible that if the peer's chain has grown (and the sync takes very long) that you could get to this condition; the right thing to do in that scenario (assuming our peer has an actually more work chain) is to try to sync with this peer again later.  (Obviously this is a pathological case, but I think we should still be able to sync such a chain anyway, eventually.)\r\n\r\nI'll update the comment.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-31T18:14:03Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934021719",
      "id" : 934021719,
      "in_reply_to_id" : 932186749,
      "line" : 225,
      "node_id" : "PRRC_kwDOABII5843rApX",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 225,
      "original_position" : 220,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 225,
      "pull_request_review_id" : 1056600826,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021719/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-31T18:14:03Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021719",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934021892"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021892"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-07-31T18:15:39Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934021892",
      "id" : 934021892,
      "in_reply_to_id" : 932282250,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843rAsE",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 29,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1056600977,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021892/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-31T18:15:39Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934021892",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934656740"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934656740"
         }
      },
      "author_association" : "MEMBER",
      "body" : "in fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf:\r\n\r\nPerhaps 25 should be named, e.g. `REDOWNLOAD_BUFFER_THRESHOLD`? IIUC it's possible to change this in the future if the optimization script outputs a different rsize?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T15:27:25Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934656740",
      "id" : 934656740,
      "line" : 10,
      "node_id" : "PRRC_kwDOABII5843tbrk",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 10,
      "original_position" : 10,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 10,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934656740/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934656740",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934663545"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934663545"
         }
      },
      "author_association" : "MEMBER",
      "body" : "in 172453aa980e7e0b9cfa616971090461a2796c09:\r\n\r\nOops! I'm sorry, I gave an incorrect suggestion before :facepalm: this would exclude node2\r\n```suggestion\r\n        self.sync_all()\r\n```",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T15:34:13Z",
      "diff_hunk" : "@@ -0,0 +1,66 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def setup_network(self):\n+        self.setup_nodes()\n+        self.connect_nodes(0, 1)\n+        self.connect_nodes(0, 2)\n+        self.sync_all(self.nodes[0:2])",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934663545",
      "id" : 934663545,
      "line" : 24,
      "node_id" : "PRRC_kwDOABII5843tdV5",
      "original_commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "original_line" : 24,
      "original_position" : 24,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 24,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934663545/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934663545",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934671923"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934671923"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit in fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf, this might be clearer:\r\n```suggestion\r\n    return std::all_of(headers.cbegin(), headers.cend(),\r\n                       [&](const auto& header) { return CheckProofOfWork(header.GetHash(), header.nBits, consensusParams);});\r\n```",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T15:43:14Z",
      "diff_hunk" : "@@ -3426,6 +3426,25 @@ std::vector<unsigned char> ChainstateManager::GenerateCoinbaseCommitment(CBlock&\n     return commitment;\n }\n \n+bool HasValidProofOfWork(const std::vector<CBlockHeader>& headers, const Consensus::Params& consensusParams)\n+{\n+    bool proof_of_work_valid = true;\n+    for (const CBlockHeader& header : headers) {\n+        proof_of_work_valid = proof_of_work_valid && CheckProofOfWork(header.GetHash(), header.nBits, consensusParams);\n+    }\n+    return proof_of_work_valid;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934671923",
      "id" : 934671923,
      "line" : 3435,
      "node_id" : "PRRC_kwDOABII5843tfYz",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 3435,
      "original_position" : 10,
      "original_start_line" : 3431,
      "path" : "src/validation.cpp",
      "position" : 10,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934671923/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 3431,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934671923",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934681520"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934681520"
         }
      },
      "author_association" : "MEMBER",
      "body" : "in 130d838df0b02f1115cb54e62002a95823d5efcb:\r\n\r\nMaybe also mention this always returns true if not on a difficulty adjustment block?",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T15:53:32Z",
      "diff_hunk" : "@@ -20,4 +20,18 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n /** Check whether a block hash satisfies the proof-of-work requirement specified by nBits */\n bool CheckProofOfWork(uint256 hash, unsigned int nBits, const Consensus::Params&);\n \n+/**\n+ * Return false if the proof-of-work requirement specified by new_nbits at a\n+ * given height is not possible, given the proof-of-work on the prior block as\n+ * specified by old_nbits.\n+ *\n+ * This function only checks that the new value is within a factor of 4 of the\n+ * old value for blocks at the difficulty adjustment interval, and otherwise\n+ * requires the values to be the same.\n+ *\n+ * Always returns true on networks where min difficulty blocks are allowed,\n+ * such as regtest/testnet.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934681520",
      "id" : 934681520,
      "line" : 33,
      "node_id" : "PRRC_kwDOABII5843thuw",
      "original_commit_id" : "130d838df0b02f1115cb54e62002a95823d5efcb",
      "original_line" : 33,
      "original_position" : 14,
      "original_start_line" : 32,
      "path" : "src/pow.h",
      "position" : 14,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934681520/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 32,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934681520",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934686816"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934686816"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit in fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf:\r\n```suggestion\r\n//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\r\nconstexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\r\n//! Pull out headers for acceptance during redownload once our buffer exceeds this number of headers\r\nconstexpr size_t REDOWNLOAD_HEADERS_THRESHOLD{25*HEADER_COMMITMENT_FREQUENCY};\r\n```",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T15:59:12Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934686816",
      "id" : 934686816,
      "line" : 10,
      "node_id" : "PRRC_kwDOABII5843tjBg",
      "original_commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "original_line" : 10,
      "original_position" : 10,
      "original_start_line" : 7,
      "path" : "src/headerssync.cpp",
      "position" : 10,
      "pull_request_review_id" : 1055426992,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934686816/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 7,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-01T16:19:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934686816",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934916850"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934916850"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I prefer doing so yes.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:01:22Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);\n+\n+        // Calculate the largest difficulty value possible:\n+        arith_uint256 bnNew;\n+        bnNew.SetCompact(old_nbits);\n+        bnNew *= largest_timespan;\n+        bnNew /= params.nPowTargetTimespan;\n+\n+        if (bnNew > bnPowLimit)\n+            bnNew = bnPowLimit;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934916850",
      "id" : 934916850,
      "in_reply_to_id" : 932235084,
      "line" : 95,
      "node_id" : "PRRC_kwDOABII5843ubLy",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 95,
      "original_position" : 25,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 25,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934916850/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934916850",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934918571"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934918571"
         }
      },
      "author_association" : "MEMBER",
      "body" : "@glozow `REDOWNLOAD_HEADERS_THRESHOLD` will (in optimal configurations) always be a multiple of `HEADER_COMMITMENT_FREQUENCY`. This could just have been written as just `= 14275;`, but that would make this multiple-of relation less clear.\r\n\r\nIf it's confusing, I would suggest instead doing:\r\n\r\n```c++\r\nconstexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\r\nconstexpr size_t REDOWNLOAD_HEADERS_FACTOR = 25;\r\n```\r\n\r\nand then replace the current instances of `REDOWNLOAD_HEADERS_THRESHOLD` with `HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_FACTOR`.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:04:10Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934918571",
      "id" : 934918571,
      "in_reply_to_id" : 934656740,
      "line" : 10,
      "node_id" : "PRRC_kwDOABII5843ubmr",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 10,
      "original_position" : 10,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 10,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934918571/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934918571",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934920798"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934920798"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Looks good.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:07:36Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934920798",
      "id" : 934920798,
      "in_reply_to_id" : 932259718,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ucJe",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 61,
      "original_position" : 61,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934920798/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934920798",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934921949"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934921949"
         }
      },
      "author_association" : "MEMBER",
      "body" : "@instagibbs In the old Satoshi-era naming convention, it referred to \"bignum\" (there was a `CBigNum` wrapper around the OpenSSL `BIGNUM` type, which was used for various big integer operations, both inside script and for PoW purposes).",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:09:28Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934921949",
      "id" : 934921949,
      "in_reply_to_id" : 932564292,
      "line" : 84,
      "node_id" : "PRRC_kwDOABII5843ucbd",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 84,
      "original_position" : 14,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 14,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934921949/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934921949",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934923131"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934923131"
         }
      },
      "author_association" : "MEMBER",
      "body" : "@glozow The testing power is significantly less if you need 16384 booleans before another allocation is made (because interactions that involve many separate allocations are much more likely to trigger bugs).",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:11:09Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934923131",
      "id" : 934923131,
      "in_reply_to_id" : 933235315,
      "line" : 19,
      "node_id" : "PRRC_kwDOABII5843uct7",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 19,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934923131/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934923131",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934933976"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934933976"
         }
      },
      "author_association" : "MEMBER",
      "body" : "@glozow @sdaftuar Added a commit that adds these to the fuzzer in https://github.com/sipa/bitcoin/commits/pr25717",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:28:42Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;\n+\n+//! Deterministic random vector of bools, for begin/end insertions to draw from.\n+std::vector<bool> RANDDATA;\n+\n+void InitRandData()\n+{\n+    FastRandomContext ctx(true);\n+    RANDDATA.clear();\n+    for (size_t i = 0; i < (1U << RANDDATA_BITS) + (1U << LEN_BITS); ++i) {\n+        RANDDATA.push_back(ctx.randbool());\n+    }\n+}\n+\n+} // namespace\n+\n+FUZZ_TARGET_INIT(bitdeque, InitRandData)\n+{\n+    FuzzedDataProvider provider(buffer.data(), buffer.size());\n+    FastRandomContext ctx(true);\n+\n+    size_t maxlen = (1U << provider.ConsumeIntegralInRange<size_t>(0, LEN_BITS)) - 1;\n+    size_t limitlen = 4 * maxlen;\n+\n+    std::deque<bool> deq;\n+    bitdeque_type bitdeq;\n+\n+    const auto& cdeq = deq;\n+    const auto& cbitdeq = bitdeq;\n+\n+    size_t initlen = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+    while (initlen) {\n+        bool val = ctx.randbool();\n+        deq.push_back(val);\n+        bitdeq.push_back(val);\n+        --initlen;\n+    }\n+\n+    while (provider.remaining_bytes()) {\n+        {\n+            assert(deq.size() == bitdeq.size());\n+            auto it = deq.begin();\n+            auto bitit = bitdeq.begin();\n+            auto itend = deq.end();\n+            while (it != itend) {\n+                assert(*it == *bitit);\n+                ++it;\n+                ++bitit;\n+            }\n+        }\n+\n+        CallOneOf(provider,\n+            [&] {\n+                // constructor()\n+                deq = std::deque<bool>{};\n+                bitdeq = bitdeque_type{};\n+            },\n+            [&] {\n+                // assign(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq.assign(count, val);\n+                bitdeq.assign(count, val);\n+            },\n+            [&] {\n+                // constructor(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq = std::deque<bool>(count, val);\n+                bitdeq = bitdeque_type(count, val);\n+            },\n+            [&] {\n+                // constructor(count)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                deq = std::deque<bool>(count);\n+                bitdeq = bitdeque_type(count);\n+            },\n+            [&] {\n+                // construct(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq = std::deque<bool>(rand_begin, rand_end);\n+                bitdeq = bitdeque_type(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // assign(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq.assign(rand_begin, rand_end);\n+                bitdeq.assign(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // construct(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = std::deque<bool>(ilist);\n+                bitdeq = bitdeque_type(ilist);\n+            },\n+            [&] {\n+                // assign(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq.assign(ilist);\n+                bitdeq.assign(ilist);\n+            },\n+            [&] {\n+                // operator=(const&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                const std::deque<bool> deq2(count, val);\n+                deq = deq2;\n+                const bitdeque_type bitdeq2(count, val);\n+                bitdeq = bitdeq2;\n+            },\n+            [&] {\n+                // operator=(&&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                std::deque<bool> deq2(count, val);\n+                deq = std::move(deq2);\n+                bitdeque_type bitdeq2(count, val);\n+                bitdeq = std::move(bitdeq2);\n+            },\n+            [&] {\n+                // deque swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                using std::swap;\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                swap(deq, deq2);\n+                swap(bitdeq, bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // deque.swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                deq.swap(deq2);\n+                bitdeq.swap(bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // operator=(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = ilist;\n+                bitdeq = ilist;\n+            },\n+            [&] {\n+                // iterator arithmetic\n+                auto pos1 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto pos2 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto it = deq.begin() + pos1;\n+                auto bitit = bitdeq.begin() + pos1;\n+                if ((size_t)pos1 != cdeq.size()) assert(*it == *bitit);\n+                assert(it - deq.begin() == pos1);\n+                assert(bitit - bitdeq.begin() == pos1);\n+                if (provider.ConsumeBool()) {\n+                    it += pos2 - pos1;\n+                    bitit += pos2 - pos1;\n+                } else {\n+                    it -= pos1 - pos2;\n+                    bitit -= pos1 - pos2;\n+                }\n+                if ((size_t)pos2 != cdeq.size()) assert(*it == *bitit);\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+                if (provider.ConsumeBool()) {\n+                    if ((size_t)pos2 != cdeq.size()) {\n+                        ++it;\n+                        ++bitit;\n+                    }\n+                } else {\n+                    if (pos2 != 0) {\n+                        --it;\n+                        --bitit;\n+                    }\n+                }\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+            },\n+            [&] {\n+                // begin() and end()\n+                assert(deq.end() - deq.begin() == bitdeq.end() - bitdeq.begin());\n+            },\n+            [&] {\n+                // begin() and end() (const)\n+                assert(cdeq.end() - cdeq.begin() == cbitdeq.end() - cbitdeq.begin());\n+            },\n+            [&] {\n+                // rbegin() and rend()\n+                assert(deq.rend() - deq.rbegin() == bitdeq.rend() - bitdeq.rbegin());\n+            },\n+            [&] {\n+                // rbegin() and rend() (const)\n+                assert(cdeq.rend() - cdeq.rbegin() == cbitdeq.rend() - cbitdeq.rbegin());\n+            },\n+            [&] {\n+                // cbegin() and cend()\n+                assert(cdeq.cend() - cdeq.cbegin() == cbitdeq.cend() - cbitdeq.cbegin());\n+            },\n+            [&] {\n+                // crbegin() and crend()\n+                assert(cdeq.crend() - cdeq.crbegin() == cbitdeq.crend() - cbitdeq.crbegin());\n+            },\n+            [&] {\n+                // size\n+                assert(cdeq.size() == cbitdeq.size());\n+            },\n+            [&] {\n+                // empty\n+                assert(cdeq.empty() == cbitdeq.empty());\n+            },\n+            [&] {\n+                // at (in range) and flip\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    auto& ref = deq.at(pos);\n+                    auto bitref = bitdeq.at(pos);\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // at (maybe out of range) and bit assign\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool newval = ctx.randbool();\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = deq.at(pos);\n+                    val_deq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = bitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // at (maybe out of range) (const)\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = cdeq.at(pos);\n+                    val_deq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = cbitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // operator[]\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                    if (ctx.randbool()) {\n+                        deq[pos] = !deq[pos];\n+                        bitdeq[pos].flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // operator[] const\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                }\n+            },\n+            [&] {\n+                // front()\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.front();\n+                    auto bitref = bitdeq.front();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref = !bitref;\n+                    }\n+                }\n+            },\n+            [&] {\n+                // front() const\n+                if (!cdeq.empty()) {\n+                    auto& ref = cdeq.front();\n+                    auto bitref = cbitdeq.front();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // back() and swap(bool, ref)\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.back();\n+                    auto bitref = bitdeq.back();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // back() const\n+                if (!cdeq.empty()) {\n+                    const auto& cdeq = deq;\n+                    const auto& cbitdeq = bitdeq;\n+                    auto& ref = cdeq.back();\n+                    auto bitref = cbitdeq.back();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // push_back()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // push_front()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_back()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 2);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_front()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(1, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // erase (in middle, single)\n+                if (!cdeq.empty()) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    size_t after = cdeq.size() - 1 - before;\n+                    auto it = deq.erase(cdeq.begin() + before);\n+                    auto bitit = bitdeq.erase(cbitdeq.begin() + before);\n+                    assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                    assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+                }\n+            },\n+            [&] {\n+                // erase (at front, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.begin(), cdeq.begin() + count);\n+                auto bitit = bitdeq.erase(cbitdeq.begin(), cbitdeq.begin() + count);\n+                assert(it == deq.begin());\n+                assert(bitit == bitdeq.begin());\n+            },\n+            [&] {\n+                // erase (at back, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.end() - count, cdeq.end());\n+                auto bitit = bitdeq.erase(cbitdeq.end() - count, cbitdeq.end());\n+                assert(it == deq.end());\n+                assert(bitit == bitdeq.end());\n+            },\n+            [&] {\n+                // erase (in middle, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - count);\n+                size_t after = cdeq.size() - count - before;\n+                auto it = deq.erase(cdeq.begin() + before, cdeq.end() - after);\n+                auto bitit = bitdeq.erase(cbitdeq.begin() + before, cbitdeq.end() - after);\n+                assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+            },\n+            [&] {\n+                // insert (in middle, single)\n+                if (cdeq.size() < limitlen) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (at front, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin(), rand_begin, rand_end);\n+                    assert(it == cdeq.begin());\n+                    assert(bitit == cbitdeq.begin());\n+                }\n+            },\n+            [&] {\n+                // insert (at back, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.end(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.end(), rand_begin, rand_end);\n+                    assert(it == cdeq.end() - count);\n+                    assert(bitit == cbitdeq.end() - count);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, range)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, count, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, count, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin() + before, rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, rand_begin, rand_end);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934933976",
      "id" : 934933976,
      "in_reply_to_id" : 933239940,
      "line" : 523,
      "node_id" : "PRRC_kwDOABII5843ufXY",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 523,
      "original_position" : 523,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 523,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934933976/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934933976",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934934877"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934934877"
         }
      },
      "author_association" : "MEMBER",
      "body" : "@glozow No, on non-difficulty-adjustment blocks it returns whether the difficulty changed.",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-01T21:30:21Z",
      "diff_hunk" : "@@ -20,4 +20,18 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n /** Check whether a block hash satisfies the proof-of-work requirement specified by nBits */\n bool CheckProofOfWork(uint256 hash, unsigned int nBits, const Consensus::Params&);\n \n+/**\n+ * Return false if the proof-of-work requirement specified by new_nbits at a\n+ * given height is not possible, given the proof-of-work on the prior block as\n+ * specified by old_nbits.\n+ *\n+ * This function only checks that the new value is within a factor of 4 of the\n+ * old value for blocks at the difficulty adjustment interval, and otherwise\n+ * requires the values to be the same.\n+ *\n+ * Always returns true on networks where min difficulty blocks are allowed,\n+ * such as regtest/testnet.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r934934877",
      "id" : 934934877,
      "in_reply_to_id" : 934681520,
      "line" : 33,
      "node_id" : "PRRC_kwDOABII5843ufld",
      "original_commit_id" : "130d838df0b02f1115cb54e62002a95823d5efcb",
      "original_line" : 33,
      "original_position" : 14,
      "original_start_line" : 32,
      "path" : "src/pow.h",
      "position" : 14,
      "pull_request_review_id" : 1055897986,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934934877/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 32,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-01T21:30:45Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/934934877",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@glozow \r\n\r\n> > It may make sense to include the script in the repository (as I can imagine it being re-run to tune things occasionally, but there should not be a need to do it more than every few years). It could also live on the devwiki or just linked-to in the code. Opinions?\r\n>\r\n> Maybe contrib/devtools? Devwiki seems fine too, no strong opinion.\r\n\r\nMy current thinking is to add it to contrib/devtools in a follow-up PR, together with instructions in the release-process to run/update it. No need to add the review burden of that here, as the current values are likely more than sufficient for at least a few years.\r\n\r\n> I have some questions trying to understand headerssync_params.py.\r\n> Why is `BLOCK_INTERVAL = timedelta(seconds=598, microseconds=800000)` rather than exactly 10min ([link](https://gist.github.com/sipa/016ae445c132cdf65a2791534dfb7ae1#file-headersync_params-py-L13))? Is it for expected hashrate increase?\r\n\r\nYes, the number is just the average block rate in 2021, approximately. It barely matters, so I've changed it to just 600 seconds. A few percent off on this value isn't going to change the result.\r\n\r\n> And based on \"especially as this attack is only possible before the victim has learned about the honest chain\" ([link](https://gist.github.com/sipa/016ae445c132cdf65a2791534dfb7ae1#file-headersync_params-py-L86-L89)) does this mean we should always attempt to sync headers from all/multiple outbound peers at once?\r\n\r\nI don't think so; that also worsens the attack potential in addition to reducing it, because it increases the chance that at least one of the nodes synced from will be an attacker, and gives them a window while the first (eventually) successful hasn't reached the second stage yet.\r\n\r\nAnd syncing from all peers at once is a pretty extreme position to take from a bandwidth optimization perspective (in non-attack scenarios). For most aspects of the P2P protocol, we attempt to never request the same thing twice simultaneously (this is true for transactions and blocks, except the high-bandwidth compact block mode which makes a bounded number of exceptions). Headers are small, so strictly requiring only a single header sync in flight is pretty extreme and opens up the ability for peers to stall the sync for a long time, but fetching from all at once means wasting possibly several GB of volume. #25720 picks something in between: start one sync for each new block announcement.",
      "created_at" : "2022-08-01T21:56:07Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1201763035",
      "id" : 1201763035,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HoXLb",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 1,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 1,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1201763035/reactions"
      },
      "updated_at" : "2022-08-02T16:49:50Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1201763035",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r935289113"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935289113"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Ah, that makes sense to me - thanks!",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-02T08:50:33Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r935289113",
      "id" : 935289113,
      "in_reply_to_id" : 933235315,
      "line" : 19,
      "node_id" : "PRRC_kwDOABII5843v2EZ",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 19,
      "pull_request_review_id" : 1058361971,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935289113/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T08:50:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935289113",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@sipa Makes sense, thanks for explaining!",
      "created_at" : "2022-08-02T16:03:40Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1202908602",
      "id" : 1202908602,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585Hsu26",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1202908602/reactions"
      },
      "updated_at" : "2022-08-02T16:03:40Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1202908602",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/25183001?v=4",
         "events_url" : "https://api.github.com/users/glozow/events{/privacy}",
         "followers_url" : "https://api.github.com/users/glozow/followers",
         "following_url" : "https://api.github.com/users/glozow/following{/other_user}",
         "gists_url" : "https://api.github.com/users/glozow/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/glozow",
         "id" : 25183001,
         "login" : "glozow",
         "node_id" : "MDQ6VXNlcjI1MTgzMDAx",
         "organizations_url" : "https://api.github.com/users/glozow/orgs",
         "received_events_url" : "https://api.github.com/users/glozow/received_events",
         "repos_url" : "https://api.github.com/users/glozow/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/glozow/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/glozow/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/glozow"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r935926734"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935926734"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Well, it could be, but the test would still be correct if `pindexLast.nBits` were modified to be within a factor of 4 from the max difficulty target.\r\n\r\nSo it seems to me that having `expected_nbts = 0x1d00ffffU` is the more important line as it captures exactly what the test case is trying to exercise here (and `pindexLast.nBits` could be set from that, or not).",
      "commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "created_at" : "2022-08-02T18:54:58Z",
      "diff_hunk" : "@@ -32,7 +34,9 @@ BOOST_AUTO_TEST_CASE(get_next_work_pow_limit)\n     pindexLast.nHeight = 2015;\n     pindexLast.nTime = 1233061996;  // Block #2015\n     pindexLast.nBits = 0x1d00ffff;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1d00ffffU);\n+    unsigned int expected_nbits = 0x1d00ffffU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r935926734",
      "id" : 935926734,
      "in_reply_to_id" : 932562089,
      "line" : 37,
      "node_id" : "PRRC_kwDOABII5843yRvO",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 37,
      "original_position" : 16,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 16,
      "pull_request_review_id" : 1059273476,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935926734/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T18:54:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/935926734",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040537"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040537"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Marking this as closed, I believe this is addressed now with the improved logging and the use of `assert_debug_log`.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:26:09Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040537",
      "id" : 936040537,
      "in_reply_to_id" : 932281150,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ythZ",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 30,
      "original_position" : 30,
      "original_start_line" : 27,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1059447041,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040537/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-02T21:26:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040537",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040744"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040744"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Also fixed now.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:26:25Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)\n+        self.sync_blocks(self.nodes[0:2])\n+\n+        self.log.info(\"Verify that node2 still has no new headers\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040744",
      "id" : 936040744,
      "in_reply_to_id" : 932288256,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ytko",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 46,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1059447322,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040744/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:26:26Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040744",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040926"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040926"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:26:39Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);\n+\n+        // Calculate the largest difficulty value possible:\n+        arith_uint256 bnNew;\n+        bnNew.SetCompact(old_nbits);\n+        bnNew *= largest_timespan;\n+        bnNew /= params.nPowTargetTimespan;\n+\n+        if (bnNew > bnPowLimit)\n+            bnNew = bnPowLimit;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936040926",
      "id" : 936040926,
      "in_reply_to_id" : 932235084,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ytne",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 95,
      "original_position" : 25,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : null,
      "pull_request_review_id" : 1059447541,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040926/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:26:39Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936040926",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936041037"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041037"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:26:50Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936041037",
      "id" : 936041037,
      "in_reply_to_id" : 932272722,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ytpN",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 50,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1059447703,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041037/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:26:50Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041037",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936041725"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041725"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I added a commit that tries to improve this.  Left it unsquashed for now so that it's easier to review; I don't believe there are any material DoS risks introduced by this change but just want to make sure we get enough eyes on this logic.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:27:51Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936041725",
      "id" : 936041725,
      "in_reply_to_id" : 932308150,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843ytz9",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 272,
      "original_position" : 272,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1059448614,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041725/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:27:51Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936041725",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936042096"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042096"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Added a comment, let me know if this is what you had in mind (or please suggest some other language?)",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:28:30Z",
      "diff_hunk" : "@@ -44,7 +48,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_lower_limit_actual)\n     pindexLast.nHeight = 68543;\n     pindexLast.nTime = 1279297671;  // Block #68543\n     pindexLast.nBits = 0x1c05a3f4;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1c0168fdU);\n+    unsigned int expected_nbits = 0x1c0168fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936042096",
      "id" : 936042096,
      "in_reply_to_id" : 932560137,
      "line" : 56,
      "node_id" : "PRRC_kwDOABII5843yt5w",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 56,
      "original_position" : 27,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 32,
      "pull_request_review_id" : 1059449206,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042096/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:28:30Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042096",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936042242"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042242"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:28:43Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936042242",
      "id" : 936042242,
      "in_reply_to_id" : 932564292,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843yt8C",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 84,
      "original_position" : 14,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : null,
      "pull_request_review_id" : 1059449397,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042242/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:28:43Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936042242",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043151"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043151"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Thanks, cherry-picked here and squashed.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:30:11Z",
      "diff_hunk" : "@@ -0,0 +1,528 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <util/bitdeque.h>\n+\n+#include <random.h>\n+#include <test/fuzz/FuzzedDataProvider.h>\n+#include <test/fuzz/util.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int LEN_BITS = 16;\n+constexpr int RANDDATA_BITS = 20;\n+\n+using bitdeque_type = bitdeque<128>;\n+\n+//! Deterministic random vector of bools, for begin/end insertions to draw from.\n+std::vector<bool> RANDDATA;\n+\n+void InitRandData()\n+{\n+    FastRandomContext ctx(true);\n+    RANDDATA.clear();\n+    for (size_t i = 0; i < (1U << RANDDATA_BITS) + (1U << LEN_BITS); ++i) {\n+        RANDDATA.push_back(ctx.randbool());\n+    }\n+}\n+\n+} // namespace\n+\n+FUZZ_TARGET_INIT(bitdeque, InitRandData)\n+{\n+    FuzzedDataProvider provider(buffer.data(), buffer.size());\n+    FastRandomContext ctx(true);\n+\n+    size_t maxlen = (1U << provider.ConsumeIntegralInRange<size_t>(0, LEN_BITS)) - 1;\n+    size_t limitlen = 4 * maxlen;\n+\n+    std::deque<bool> deq;\n+    bitdeque_type bitdeq;\n+\n+    const auto& cdeq = deq;\n+    const auto& cbitdeq = bitdeq;\n+\n+    size_t initlen = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+    while (initlen) {\n+        bool val = ctx.randbool();\n+        deq.push_back(val);\n+        bitdeq.push_back(val);\n+        --initlen;\n+    }\n+\n+    while (provider.remaining_bytes()) {\n+        {\n+            assert(deq.size() == bitdeq.size());\n+            auto it = deq.begin();\n+            auto bitit = bitdeq.begin();\n+            auto itend = deq.end();\n+            while (it != itend) {\n+                assert(*it == *bitit);\n+                ++it;\n+                ++bitit;\n+            }\n+        }\n+\n+        CallOneOf(provider,\n+            [&] {\n+                // constructor()\n+                deq = std::deque<bool>{};\n+                bitdeq = bitdeque_type{};\n+            },\n+            [&] {\n+                // assign(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq.assign(count, val);\n+                bitdeq.assign(count, val);\n+            },\n+            [&] {\n+                // constructor(count, val)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                deq = std::deque<bool>(count, val);\n+                bitdeq = bitdeque_type(count, val);\n+            },\n+            [&] {\n+                // constructor(count)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                deq = std::deque<bool>(count);\n+                bitdeq = bitdeque_type(count);\n+            },\n+            [&] {\n+                // construct(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq = std::deque<bool>(rand_begin, rand_end);\n+                bitdeq = bitdeque_type(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // assign(begin, end)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                deq.assign(rand_begin, rand_end);\n+                bitdeq.assign(rand_begin, rand_end);\n+            },\n+            [&] {\n+                // construct(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = std::deque<bool>(ilist);\n+                bitdeq = bitdeque_type(ilist);\n+            },\n+            [&] {\n+                // assign(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq.assign(ilist);\n+                bitdeq.assign(ilist);\n+            },\n+            [&] {\n+                // operator=(const&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                const std::deque<bool> deq2(count, val);\n+                deq = deq2;\n+                const bitdeque_type bitdeq2(count, val);\n+                bitdeq = bitdeq2;\n+            },\n+            [&] {\n+                // operator=(&&)\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                bool val = ctx.randbool();\n+                std::deque<bool> deq2(count, val);\n+                deq = std::move(deq2);\n+                bitdeque_type bitdeq2(count, val);\n+                bitdeq = std::move(bitdeq2);\n+            },\n+            [&] {\n+                // deque swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                using std::swap;\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                swap(deq, deq2);\n+                swap(bitdeq, bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // deque.swap\n+                auto count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                auto rand_end = rand_begin + count;\n+                std::deque<bool> deq2(rand_begin, rand_end);\n+                bitdeque_type bitdeq2(rand_begin, rand_end);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+                deq.swap(deq2);\n+                bitdeq.swap(bitdeq2);\n+                assert(deq.size() == bitdeq.size());\n+                assert(deq2.size() == bitdeq2.size());\n+            },\n+            [&] {\n+                // operator=(initializer_list)\n+                std::initializer_list<bool> ilist{ctx.randbool(), ctx.randbool(), ctx.randbool()};\n+                deq = ilist;\n+                bitdeq = ilist;\n+            },\n+            [&] {\n+                // iterator arithmetic\n+                auto pos1 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto pos2 = provider.ConsumeIntegralInRange<long>(0, cdeq.size());\n+                auto it = deq.begin() + pos1;\n+                auto bitit = bitdeq.begin() + pos1;\n+                if ((size_t)pos1 != cdeq.size()) assert(*it == *bitit);\n+                assert(it - deq.begin() == pos1);\n+                assert(bitit - bitdeq.begin() == pos1);\n+                if (provider.ConsumeBool()) {\n+                    it += pos2 - pos1;\n+                    bitit += pos2 - pos1;\n+                } else {\n+                    it -= pos1 - pos2;\n+                    bitit -= pos1 - pos2;\n+                }\n+                if ((size_t)pos2 != cdeq.size()) assert(*it == *bitit);\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+                if (provider.ConsumeBool()) {\n+                    if ((size_t)pos2 != cdeq.size()) {\n+                        ++it;\n+                        ++bitit;\n+                    }\n+                } else {\n+                    if (pos2 != 0) {\n+                        --it;\n+                        --bitit;\n+                    }\n+                }\n+                assert(deq.end() - it == bitdeq.end() - bitit);\n+            },\n+            [&] {\n+                // begin() and end()\n+                assert(deq.end() - deq.begin() == bitdeq.end() - bitdeq.begin());\n+            },\n+            [&] {\n+                // begin() and end() (const)\n+                assert(cdeq.end() - cdeq.begin() == cbitdeq.end() - cbitdeq.begin());\n+            },\n+            [&] {\n+                // rbegin() and rend()\n+                assert(deq.rend() - deq.rbegin() == bitdeq.rend() - bitdeq.rbegin());\n+            },\n+            [&] {\n+                // rbegin() and rend() (const)\n+                assert(cdeq.rend() - cdeq.rbegin() == cbitdeq.rend() - cbitdeq.rbegin());\n+            },\n+            [&] {\n+                // cbegin() and cend()\n+                assert(cdeq.cend() - cdeq.cbegin() == cbitdeq.cend() - cbitdeq.cbegin());\n+            },\n+            [&] {\n+                // crbegin() and crend()\n+                assert(cdeq.crend() - cdeq.crbegin() == cbitdeq.crend() - cbitdeq.crbegin());\n+            },\n+            [&] {\n+                // size\n+                assert(cdeq.size() == cbitdeq.size());\n+            },\n+            [&] {\n+                // empty\n+                assert(cdeq.empty() == cbitdeq.empty());\n+            },\n+            [&] {\n+                // at (in range) and flip\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    auto& ref = deq.at(pos);\n+                    auto bitref = bitdeq.at(pos);\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // at (maybe out of range) and bit assign\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool newval = ctx.randbool();\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = deq.at(pos);\n+                    val_deq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = bitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                    ref = newval;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // at (maybe out of range) (const)\n+                size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() + maxlen);\n+                bool throw_deq{false}, throw_bitdeq{false};\n+                bool val_deq{false}, val_bitdeq{false};\n+                try {\n+                    auto& ref = cdeq.at(pos);\n+                    val_deq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_deq = true;\n+                }\n+                try {\n+                    auto ref = cbitdeq.at(pos);\n+                    val_bitdeq = ref;\n+                } catch (const std::out_of_range&) {\n+                    throw_bitdeq = true;\n+                }\n+                assert(throw_deq == throw_bitdeq);\n+                assert(throw_bitdeq == pos >= cdeq.size());\n+                if (!throw_deq) assert(val_deq == val_bitdeq);\n+            },\n+            [&] {\n+                // operator[]\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                    if (ctx.randbool()) {\n+                        deq[pos] = !deq[pos];\n+                        bitdeq[pos].flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // operator[] const\n+                if (!cdeq.empty()) {\n+                    size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    assert(deq[pos] == bitdeq[pos]);\n+                }\n+            },\n+            [&] {\n+                // front()\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.front();\n+                    auto bitref = bitdeq.front();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref = !bitref;\n+                    }\n+                }\n+            },\n+            [&] {\n+                // front() const\n+                if (!cdeq.empty()) {\n+                    auto& ref = cdeq.front();\n+                    auto bitref = cbitdeq.front();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // back() and swap(bool, ref)\n+                if (!cdeq.empty()) {\n+                    auto& ref = deq.back();\n+                    auto bitref = bitdeq.back();\n+                    assert(ref == bitref);\n+                    if (ctx.randbool()) {\n+                        ref = !ref;\n+                        bitref.flip();\n+                    }\n+                }\n+            },\n+            [&] {\n+                // back() const\n+                if (!cdeq.empty()) {\n+                    const auto& cdeq = deq;\n+                    const auto& cbitdeq = bitdeq;\n+                    auto& ref = cdeq.back();\n+                    auto bitref = cbitdeq.back();\n+                    assert(ref == bitref);\n+                }\n+            },\n+            [&] {\n+                // push_back()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_back(val);\n+                        bitdeq.push_back(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // push_front()\n+                if (cdeq.size() < limitlen) {\n+                    bool val = ctx.randbool();\n+                    if (cdeq.empty()) {\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.push_front(val);\n+                        bitdeq.push_front(val);\n+                        assert(ref == bitref); // references are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_back()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 2);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_back();\n+                        bitdeq.pop_back();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // pop_front()\n+                if (!cdeq.empty()) {\n+                    if (cdeq.size() == 1) {\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                    } else {\n+                        size_t pos = provider.ConsumeIntegralInRange<size_t>(1, cdeq.size() - 1);\n+                        auto& ref = deq[pos];\n+                        auto bitref = bitdeq[pos];\n+                        assert(ref == bitref);\n+                        deq.pop_front();\n+                        bitdeq.pop_front();\n+                        assert(ref == bitref); // references to other elements are not invalidated\n+                    }\n+                }\n+            },\n+            [&] {\n+                // erase (in middle, single)\n+                if (!cdeq.empty()) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - 1);\n+                    size_t after = cdeq.size() - 1 - before;\n+                    auto it = deq.erase(cdeq.begin() + before);\n+                    auto bitit = bitdeq.erase(cbitdeq.begin() + before);\n+                    assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                    assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+                }\n+            },\n+            [&] {\n+                // erase (at front, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.begin(), cdeq.begin() + count);\n+                auto bitit = bitdeq.erase(cbitdeq.begin(), cbitdeq.begin() + count);\n+                assert(it == deq.begin());\n+                assert(bitit == bitdeq.begin());\n+            },\n+            [&] {\n+                // erase (at back, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                auto it = deq.erase(cdeq.end() - count, cdeq.end());\n+                auto bitit = bitdeq.erase(cbitdeq.end() - count, cbitdeq.end());\n+                assert(it == deq.end());\n+                assert(bitit == bitdeq.end());\n+            },\n+            [&] {\n+                // erase (in middle, range)\n+                size_t count = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size() - count);\n+                size_t after = cdeq.size() - count - before;\n+                auto it = deq.erase(cdeq.begin() + before, cdeq.end() - after);\n+                auto bitit = bitdeq.erase(cbitdeq.begin() + before, cbitdeq.end() - after);\n+                assert(it == cdeq.begin() + before && it == cdeq.end() - after);\n+                assert(bitit == cbitdeq.begin() + before && bitit == cbitdeq.end() - after);\n+            },\n+            [&] {\n+                // insert (in middle, single)\n+                if (cdeq.size() < limitlen) {\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (at front, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin(), rand_begin, rand_end);\n+                    assert(it == cdeq.begin());\n+                    assert(bitit == cbitdeq.begin());\n+                }\n+            },\n+            [&] {\n+                // insert (at back, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.end(), rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.end(), rand_begin, rand_end);\n+                    assert(it == cdeq.end() - count);\n+                    assert(bitit == cbitdeq.end() - count);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, range)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    bool val = ctx.randbool();\n+                    auto it = deq.insert(cdeq.begin() + before, count, val);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, count, val);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }\n+            },\n+            [&] {\n+                // insert (in middle, begin/end)\n+                if (cdeq.size() < limitlen) {\n+                    size_t count = provider.ConsumeIntegralInRange<size_t>(0, maxlen);\n+                    size_t before = provider.ConsumeIntegralInRange<size_t>(0, cdeq.size());\n+                    auto rand_begin = RANDDATA.begin() + ctx.randbits(RANDDATA_BITS);\n+                    auto rand_end = rand_begin + count;\n+                    auto it = deq.insert(cdeq.begin() + before, rand_begin, rand_end);\n+                    auto bitit = bitdeq.insert(cbitdeq.begin() + before, rand_begin, rand_end);\n+                    assert(it == deq.begin() + before);\n+                    assert(bitit == bitdeq.begin() + before);\n+                }",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043151",
      "id" : 936043151,
      "in_reply_to_id" : 933239940,
      "line" : 537,
      "node_id" : "PRRC_kwDOABII5843yuKP",
      "original_commit_id" : "5072054428fa9229a0e34b9eb4a0eed97639012d",
      "original_line" : 537,
      "original_position" : 523,
      "original_start_line" : null,
      "path" : "src/test/fuzz/bitdeque.cpp",
      "position" : 537,
      "pull_request_review_id" : 1059450674,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043151/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:30:11Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043151",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043281"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043281"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Thanks, done.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:30:22Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043281",
      "id" : 936043281,
      "in_reply_to_id" : 934656740,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843yuMR",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 10,
      "original_position" : 10,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1059450835,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043281/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:30:22Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043281",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043450"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043450"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Oops I should have caught that too.  Fixed!",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:30:39Z",
      "diff_hunk" : "@@ -0,0 +1,66 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+NODE1_BLOCKS_REQUIRED = 15\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 15 blocks on top of the genesis block; node2 requires 2047\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def setup_network(self):\n+        self.setup_nodes()\n+        self.connect_nodes(0, 1)\n+        self.connect_nodes(0, 2)\n+        self.sync_all(self.nodes[0:2])",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936043450",
      "id" : 936043450,
      "in_reply_to_id" : 934663545,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843yuO6",
      "original_commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "original_line" : 24,
      "original_position" : 24,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : null,
      "pull_request_review_id" : 1059451087,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043450/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:30:39Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936043450",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936044329"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936044329"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think I prefer to just not check anything for chains where proof-of-work isn't an anti-DoS mechanism for us; seems like it avoids a false sense of security (and it doesn't accomplish anything anyway, as an attacker would just avoid failing such a check without expending any real resources).",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:31:58Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936044329",
      "id" : 936044329,
      "in_reply_to_id" : 932566102,
      "line" : 78,
      "node_id" : "PRRC_kwDOABII5843yucp",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 78,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 8,
      "pull_request_review_id" : 1059452250,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936044329/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-02T21:32:25Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936044329",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936048510"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936048510"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done, thanks.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:38:39Z",
      "diff_hunk" : "@@ -3426,6 +3426,25 @@ std::vector<unsigned char> ChainstateManager::GenerateCoinbaseCommitment(CBlock&\n     return commitment;\n }\n \n+bool HasValidProofOfWork(const std::vector<CBlockHeader>& headers, const Consensus::Params& consensusParams)\n+{\n+    bool proof_of_work_valid = true;\n+    for (const CBlockHeader& header : headers) {\n+        proof_of_work_valid = proof_of_work_valid && CheckProofOfWork(header.GetHash(), header.nBits, consensusParams);\n+    }\n+    return proof_of_work_valid;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936048510",
      "id" : 936048510,
      "in_reply_to_id" : 934671923,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843yvd-",
      "original_commit_id" : "fe620e1a1fb2ef11d06cf941249ad4e5e4250bbf",
      "original_line" : 3435,
      "original_position" : 10,
      "original_start_line" : 3431,
      "path" : "src/validation.cpp",
      "position" : null,
      "pull_request_review_id" : 1059457865,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936048510/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-02T21:38:39Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936048510",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936049872"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936049872"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Done.",
      "commit_id" : "e94ea7f3617db3f4b1972dd9c229baad4d4a9656",
      "created_at" : "2022-08-02T21:40:39Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+//! Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936049872",
      "id" : 936049872,
      "in_reply_to_id" : 934686816,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843yvzQ",
      "original_commit_id" : "e3260960add016aeb43d0be4c5b735418e37c4a7",
      "original_line" : 10,
      "original_position" : 10,
      "original_start_line" : 7,
      "path" : "src/headerssync.cpp",
      "position" : null,
      "pull_request_review_id" : 1059459507,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936049872/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : "RIGHT",
      "updated_at" : "2022-08-02T21:40:40Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936049872",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936071181"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936071181"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "It might save a few operations to first check if the new target is larger or smaller than the old one, and conditional on that run only one of the two checks.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-02T22:17:26Z",
      "diff_hunk" : "@@ -71,6 +71,57 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 pow_limit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936071181",
      "id" : 936071181,
      "line" : 86,
      "node_id" : "PRRC_kwDOABII5843y1AN",
      "original_commit_id" : "68c05de96a5b8d0b9a7122d964fe1c9704e2135d",
      "original_line" : 86,
      "original_position" : 16,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 16,
      "pull_request_review_id" : 1059486854,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936071181/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T05:03:18Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936071181",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936085122"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936085122"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Would we actually receive headers messages during initial-headers-sync without this commit? As I wrote [here](https://github.com/bitcoin/bitcoin/pull/25720#discussion_r935756421), I got the impression that other peers revert to Inv when they found a new block during headers sync and won't send us unrequested headers messages anyway, so I wonder if delaying `SENDHEADERS` actually has an effect.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-02T22:45:27Z",
      "diff_hunk" : "@@ -5076,6 +5072,24 @@ bool PeerManagerImpl::SendMessages(CNode* pto)\n \n     MaybeSendAddr(*pto, *peer, current_time);\n \n+    // Delay sending SENDHEADERS (BIP 130) until we're done with an\n+    // initial-headers-sync with this peer. Receiving headers announcements for",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936085122",
      "id" : 936085122,
      "line" : 5076,
      "node_id" : "PRRC_kwDOABII5843y4aC",
      "original_commit_id" : "c64d02a21dee37372822d2f85149606f9b1a6875",
      "original_line" : 5076,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 423,
      "pull_request_review_id" : 1059486854,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936085122/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T05:11:38Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936085122",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936216176"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936216176"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "I think it would be good to have some unconditional logging during the first phase, because the node is currently quiet for possibly minutes after startup, which might lead users to think the node is stuck. Currently, the \"Synchronizing blockheaders, height: (...) (~(...)%)\" messages only start in the redownload phase. We should probably not log too much to prevent possible disk-filling attacks caused by a low-work header chain, but at least announcing the start of each phase would be nice.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T04:07:17Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936216176",
      "id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII5843zYZw",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1059486854,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936216176/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T05:03:18Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936216176",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936232102"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936232102"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "I can't really relate this comment to the implementation. From what I understand we accept all received headers in phase 2 to memory (`m_redownloaded_headers`), but only accept them to the block index once there are `REDOWNLOAD_HEADERS_CHECK_BITS` correct commitments on top of them - with the batch size N of headers that are being accepted to the block index being just an (unimportant) consequence of the batch size in which we happen to receive headers from peers (2000 once the lookahead buffer is filled)?",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T04:49:25Z",
      "diff_hunk" : "@@ -0,0 +1,256 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <arith_uint256.h>\n+#include <chain.h>\n+#include <consensus/params.h>\n+#include <net.h> // For NodeId\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <util/bitdeque.h>\n+#include <util/hasher.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936232102",
      "id" : 936232102,
      "line" : null,
      "node_id" : "PRRC_kwDOABII5843zcSm",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 95,
      "original_position" : 95,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : null,
      "pull_request_review_id" : 1059486854,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936232102/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T05:03:18Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936232102",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936626595"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936626595"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I believe it is possible, for 2 main reasons: (1) BIP 130 has no explicit rules around when headers may be used to announce a block, so in theory any software implementing BIP 130 might be free to send a header to us regardless of whether we've completed header sync; (2) Bitcoin Core implementations would send us announcements via header at the end of our phase 1 download (if we reach their tip at the end of that phase, which is certainly possible).  So I think delaying `sendheaders` helps eliminate the common cases of how we might get a spurious headers message during our sync.\r\n",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T12:53:44Z",
      "diff_hunk" : "@@ -5076,6 +5072,24 @@ bool PeerManagerImpl::SendMessages(CNode* pto)\n \n     MaybeSendAddr(*pto, *peer, current_time);\n \n+    // Delay sending SENDHEADERS (BIP 130) until we're done with an\n+    // initial-headers-sync with this peer. Receiving headers announcements for",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936626595",
      "id" : 936626595,
      "in_reply_to_id" : 936085122,
      "line" : 5076,
      "node_id" : "PRRC_kwDOABII584308mj",
      "original_commit_id" : "c64d02a21dee37372822d2f85149606f9b1a6875",
      "original_line" : 5076,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 423,
      "pull_request_review_id" : 1060249068,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936626595/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T12:53:44Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936626595",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936878007"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936878007"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I updated the comment to hopefully make more sense and better match how we're thinking about this; let me know if it reads better now.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:17:55Z",
      "diff_hunk" : "@@ -0,0 +1,256 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <arith_uint256.h>\n+#include <chain.h>\n+#include <consensus/params.h>\n+#include <net.h> // For NodeId\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <util/bitdeque.h>\n+#include <util/hasher.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936878007",
      "id" : 936878007,
      "in_reply_to_id" : 936232102,
      "line" : null,
      "node_id" : "PRRC_kwDOABII584315-3",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 95,
      "original_position" : 95,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : null,
      "pull_request_review_id" : 1060631981,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936878007/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:17:55Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936878007",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936882362"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936882362"
         }
      },
      "author_association" : "MEMBER",
      "body" : "So if I add unconditional logging on starting a sync, then in the absence of a rate limiter I think it'd be easy for someone to fill up our disk by starting and restarting syncs with us.  Perhaps I can log at most once per peer connection when we start a low-work headers sync, what do you think?",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:19:21Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936882362",
      "id" : 936882362,
      "in_reply_to_id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII584317C6",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1060639280,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 1,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 1,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936882362/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:19:22Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936882362",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936902553"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936902553"
         }
      },
      "author_association" : "MEMBER",
      "body" : "maybe a per connection per X seconds, which would give consistent feedback that's ratelimited?",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:27:38Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936902553",
      "id" : 936902553,
      "in_reply_to_id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII58431_-Z",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1060675384,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936902553/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:27:38Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936902553",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936906842"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936906842"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Ideally, I'd say, we produce header sync progress updates based on the longest currently-ongoing header sync across all peers. That sounds like a pain to implement, though.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:30:31Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936906842",
      "id" : 936906842,
      "in_reply_to_id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII58432BBa",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1060680877,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936906842/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:30:31Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936906842",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936915939"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936915939"
         }
      },
      "author_association" : "MEMBER",
      "body" : "An additional complication in logging is that the first phase takes place entirely in net_processing, in per-peer datastructures. There is no interaction with validation, which currently emits the header sync progress updates, until the second phase.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:40:09Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936915939",
      "id" : 936915939,
      "in_reply_to_id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII58432DPj",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1060692987,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936915939/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:40:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936915939",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936919365"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936919365"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Maybe once per connection, and excluding inbound peers would be safe? Alternatively, we could log something once on startup if our best chain is below `nMinimumChainWork`. I'm thinking of the typical case of a new node without any headers starting up.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T16:43:57Z",
      "diff_hunk" : "@@ -2483,25 +2683,31 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n     }\n \n     // At this point, the headers connect to something in our block index.\n-    if (!CheckHeadersAreContinuous(headers)) {\n-        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+    // Do anti-DoS checks to determine if we should process or store for later\n+    // processing.\n+    if (!already_validated_work && TryLowWorkHeadersSync(peer, pfrom,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936919365",
      "id" : 936919365,
      "in_reply_to_id" : 936216176,
      "line" : 2695,
      "node_id" : "PRRC_kwDOABII58432EFF",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 2695,
      "original_position" : 270,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 293,
      "pull_request_review_id" : 1060697684,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936919365/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T16:43:57Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/936919365",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r937145579"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/937145579"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Thanks, it reads well now!",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-03T21:16:31Z",
      "diff_hunk" : "@@ -0,0 +1,256 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <arith_uint256.h>\n+#include <chain.h>\n+#include <consensus/params.h>\n+#include <net.h> // For NodeId\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <util/bitdeque.h>\n+#include <util/hasher.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r937145579",
      "id" : 937145579,
      "in_reply_to_id" : 936232102,
      "line" : null,
      "node_id" : "PRRC_kwDOABII584327Tr",
      "original_commit_id" : "6335a03b9e98394e28f8feab3fbade502ac1bbc2",
      "original_line" : 95,
      "original_position" : 95,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : null,
      "pull_request_review_id" : 1061022786,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/937145579/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-03T21:16:31Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/937145579",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938148745"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938148745"
         }
      },
      "author_association" : "CONTRIBUTOR",
      "body" : "Would it be possible to also add `PermittedDifficultyTransition()` coverage to the fuzz test `src/test/fuzz/pow.cpp`? I'm thinking of something like combining it with the new target from `GetNextWorkRequired()`, and then asserting that the resulting transition passes `PermittedDifficultyTransition()`.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-04T18:50:39Z",
      "diff_hunk" : "@@ -71,6 +71,57 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938148745",
      "id" : 938148745,
      "line" : 76,
      "node_id" : "PRRC_kwDOABII58436wOJ",
      "original_commit_id" : "68c05de96a5b8d0b9a7122d964fe1c9704e2135d",
      "original_line" : 76,
      "original_position" : 6,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 6,
      "pull_request_review_id" : 1062449560,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938148745/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T16:02:35Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938148745",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/48763452?v=4",
         "events_url" : "https://api.github.com/users/mzumsande/events{/privacy}",
         "followers_url" : "https://api.github.com/users/mzumsande/followers",
         "following_url" : "https://api.github.com/users/mzumsande/following{/other_user}",
         "gists_url" : "https://api.github.com/users/mzumsande/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/mzumsande",
         "id" : 48763452,
         "login" : "mzumsande",
         "node_id" : "MDQ6VXNlcjQ4NzYzNDUy",
         "organizations_url" : "https://api.github.com/users/mzumsande/orgs",
         "received_events_url" : "https://api.github.com/users/mzumsande/received_events",
         "repos_url" : "https://api.github.com/users/mzumsande/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/mzumsande/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/mzumsande/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/mzumsande"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938907402"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938907402"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: note to other reviewers: when using this code to sync from the genesis block in the year 2100, `m_max_commitments` would be about 32 million. That's less than 4 MB per peer, assuming `bitdeque` has low overhead.\r\n\r\nOf course by that time the baked in value of `nMinimumChainWork` might be too low.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T15:01:30Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938907402",
      "id" : 938907402,
      "line" : 68,
      "node_id" : "PRRC_kwDOABII58439pcK",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 69,
      "original_position" : 69,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 69,
      "pull_request_review_id" : 1063495599,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938907402/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T17:33:52Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938907402",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938950210"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938950210"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d  nit: it's a period or interval, not a frequency (which would be 1/571)",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T15:52:07Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938950210",
      "id" : 938950210,
      "line" : 8,
      "node_id" : "PRRC_kwDOABII58439z5C",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 8,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 8,
      "pull_request_review_id" : 1063495599,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938950210/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T16:16:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938950210",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938963599"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938963599"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I'm still a bit unclear on the sequence of calls here. Why are there two checks for non-full messages with low-work? ",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T16:08:54Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938963599",
      "id" : 938963599,
      "line" : 109,
      "node_id" : "PRRC_kwDOABII584393KP",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 110,
      "original_position" : 110,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 110,
      "pull_request_review_id" : 1063495599,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938963599/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T16:16:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938963599",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938966167"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938966167"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: it would be good to have a log message when the state switches to `REDOWNLOAD`.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T16:12:09Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);\n+            Finalize();\n+            return ret;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return ret;\n+            }\n+        }\n+\n+        ret.success = true;\n+        // Return any headers that are ready for acceptance.\n+        ret.headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return ret;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return ret;\n+        }\n+    }\n+    return ret;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Somehow our peer gave us a header that doesn't connect.\n+        // This might be benign -- perhaps we issued an extra getheaders\n+        // message, such as after a block INV was received.\n+        // Or it could be that our peer is broken or malicious. If broken,\n+        // sending a new getheaders immediately could trigger an infinite\n+        // loop. Just give up for now; if our peer ever gives us an block\n+        // INV later we will fetch headers then, and likely retrigger this\n+        // logic.\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash = m_chain_start->GetBlockHash();\n+        m_download_state = State::REDOWNLOAD;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938966167",
      "id" : 938966167,
      "line" : 191,
      "node_id" : "PRRC_kwDOABII584393yX",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 192,
      "original_position" : 192,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 192,
      "pull_request_review_id" : 1063495599,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938966167/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T16:16:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938966167",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938967065"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938967065"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d : can you add the height to this message? That and a message when the state changes, makes it easier to follow what's happening in the `-debug=net` log.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T16:13:24Z",
      "diff_hunk" : "@@ -2309,6 +2379,100 @@ bool PeerManagerImpl::CheckHeadersAreContinuous(const std::vector<CBlockHeader>&\n     return true;\n }\n \n+bool PeerManagerImpl::IsContinuationOfLowWorkHeadersSync(Peer& peer, CNode& pfrom, const std::vector<CBlockHeader>& headers, std::vector<CBlockHeader>& previously_downloaded_headers)\n+{\n+    if (peer.m_headers_sync) {\n+        auto result = peer.m_headers_sync->ProcessNextHeaders(headers, headers.size() == MAX_HEADERS_RESULTS);\n+        if (result.locator) {\n+            // If we get back a locator, it should not be empty\n+            Assume(!result.locator->vHave.empty());\n+            if (!result.locator->vHave.empty()) {\n+                // It should be impossible for the getheaders request to fail,\n+                // because we should have cleared the last getheaders timestamp\n+                // when processing the headers that triggered this call. But\n+                // it may be possible to bypass this via compactblock\n+                // processing, so check the result before logging just to be\n+                // safe.\n+                bool sent_getheaders = MaybeSendGetHeaders(pfrom, *result.locator, peer);\n+                if (sent_getheaders) {\n+                    LogPrint(BCLog::NET, \"more getheaders (from %s) to peer=%d\\n\",\n+                            result.locator->vHave.front().ToString(), pfrom.GetId());\n+                }\n+            }\n+        }\n+\n+        if (peer.m_headers_sync->GetState() == HeadersSyncState::State::FINAL) {\n+            peer.m_headers_sync.reset(nullptr);\n+        }\n+\n+        previously_downloaded_headers.swap(result.headers_to_process);\n+\n+        if (previously_downloaded_headers.empty() && result.success) {\n+            // If nothing else was returned and processing was successful, then\n+            // we're all done.\n+            return true;\n+        }\n+    }\n+    // Either we didn't have a sync in progress, or something went wrong\n+    // processing these headers, or we are returning headers to the caller to\n+    // process.\n+    return false;\n+}\n+\n+bool PeerManagerImpl::TryLowWorkHeadersSync(Peer& peer, CNode& pfrom, const CBlockIndex* chain_start_header, const std::vector<CBlockHeader>& headers)\n+{\n+    // Calculate the total work on this chain.\n+    arith_uint256 total_work = chain_start_header->nChainWork + CalculateHeadersWork(headers);\n+\n+    // Our dynamic anti-DoS threshold (minimum work required on a headers chain\n+    // before we'll store it)\n+    arith_uint256 minimum_chain_work = GetAntiDoSWorkThreshold();\n+\n+    // Avoid DoS via low-difficulty-headers by only processing if the headers\n+    // are part of a chain with sufficient work.\n+    if (total_work < minimum_chain_work) {\n+        // Only try to sync with this peer if their headers message was full;\n+        // otherwise they don't have more headers after this so no point in\n+        // trying to sync their too-little-work chain.\n+        if (headers.size() == MAX_HEADERS_RESULTS) {\n+            // Note: we could advance to the last header in this set that is\n+            // known to us, rather than starting at the first header (which we\n+            // may already have). But we actually might have all the headers in\n+            // this set already, because headers sync can be imprecise when a\n+            // peer has to serve us a long chain (due to imprecision in the way\n+            // locators are calculated). So philosophically, if we wanted to\n+            // optimize this correctly, we could consider requesting more\n+            // headers until we find the peer's first new header on this chain,\n+            // and start the sync from there. In practice this is unlikely to\n+            // matter much outside of initial sync, which we generally only do\n+            // once, so for now we'll just start the sync with the first header\n+            // in the set and not worry about this issue.\n+            peer.m_headers_sync.reset(new HeadersSyncState(peer.m_id, m_chainparams.GetConsensus()));\n+            if (std::optional<CBlockLocator> locator =\n+                    peer.m_headers_sync->StartInitialDownload(chain_start_header,\n+                        headers, minimum_chain_work,\n+                        m_chainman.ActiveChain().GetLocator(chain_start_header)))\n+            {\n+                Assume(!locator->vHave.empty());\n+                if (!locator->vHave.empty() && MaybeSendGetHeaders(pfrom, *locator, peer)) {\n+                    LogPrint(BCLog::NET, \"more getheaders (from %s) to end to peer=%d\\n\",",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r938967065",
      "id" : 938967065,
      "line" : 2465,
      "node_id" : "PRRC_kwDOABII584394AZ",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 2458,
      "original_position" : 184,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 184,
      "pull_request_review_id" : 1063495599,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938967065/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T16:16:58Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/938967065",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939062349"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939062349"
         }
      },
      "author_association" : "MEMBER",
      "body" : "But see also this discussion on logging: https://github.com/bitcoin/bitcoin/pull/25717#discussion_r936216176",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T18:19:49Z",
      "diff_hunk" : "@@ -2309,6 +2379,100 @@ bool PeerManagerImpl::CheckHeadersAreContinuous(const std::vector<CBlockHeader>&\n     return true;\n }\n \n+bool PeerManagerImpl::IsContinuationOfLowWorkHeadersSync(Peer& peer, CNode& pfrom, const std::vector<CBlockHeader>& headers, std::vector<CBlockHeader>& previously_downloaded_headers)\n+{\n+    if (peer.m_headers_sync) {\n+        auto result = peer.m_headers_sync->ProcessNextHeaders(headers, headers.size() == MAX_HEADERS_RESULTS);\n+        if (result.locator) {\n+            // If we get back a locator, it should not be empty\n+            Assume(!result.locator->vHave.empty());\n+            if (!result.locator->vHave.empty()) {\n+                // It should be impossible for the getheaders request to fail,\n+                // because we should have cleared the last getheaders timestamp\n+                // when processing the headers that triggered this call. But\n+                // it may be possible to bypass this via compactblock\n+                // processing, so check the result before logging just to be\n+                // safe.\n+                bool sent_getheaders = MaybeSendGetHeaders(pfrom, *result.locator, peer);\n+                if (sent_getheaders) {\n+                    LogPrint(BCLog::NET, \"more getheaders (from %s) to peer=%d\\n\",\n+                            result.locator->vHave.front().ToString(), pfrom.GetId());\n+                }\n+            }\n+        }\n+\n+        if (peer.m_headers_sync->GetState() == HeadersSyncState::State::FINAL) {\n+            peer.m_headers_sync.reset(nullptr);\n+        }\n+\n+        previously_downloaded_headers.swap(result.headers_to_process);\n+\n+        if (previously_downloaded_headers.empty() && result.success) {\n+            // If nothing else was returned and processing was successful, then\n+            // we're all done.\n+            return true;\n+        }\n+    }\n+    // Either we didn't have a sync in progress, or something went wrong\n+    // processing these headers, or we are returning headers to the caller to\n+    // process.\n+    return false;\n+}\n+\n+bool PeerManagerImpl::TryLowWorkHeadersSync(Peer& peer, CNode& pfrom, const CBlockIndex* chain_start_header, const std::vector<CBlockHeader>& headers)\n+{\n+    // Calculate the total work on this chain.\n+    arith_uint256 total_work = chain_start_header->nChainWork + CalculateHeadersWork(headers);\n+\n+    // Our dynamic anti-DoS threshold (minimum work required on a headers chain\n+    // before we'll store it)\n+    arith_uint256 minimum_chain_work = GetAntiDoSWorkThreshold();\n+\n+    // Avoid DoS via low-difficulty-headers by only processing if the headers\n+    // are part of a chain with sufficient work.\n+    if (total_work < minimum_chain_work) {\n+        // Only try to sync with this peer if their headers message was full;\n+        // otherwise they don't have more headers after this so no point in\n+        // trying to sync their too-little-work chain.\n+        if (headers.size() == MAX_HEADERS_RESULTS) {\n+            // Note: we could advance to the last header in this set that is\n+            // known to us, rather than starting at the first header (which we\n+            // may already have). But we actually might have all the headers in\n+            // this set already, because headers sync can be imprecise when a\n+            // peer has to serve us a long chain (due to imprecision in the way\n+            // locators are calculated). So philosophically, if we wanted to\n+            // optimize this correctly, we could consider requesting more\n+            // headers until we find the peer's first new header on this chain,\n+            // and start the sync from there. In practice this is unlikely to\n+            // matter much outside of initial sync, which we generally only do\n+            // once, so for now we'll just start the sync with the first header\n+            // in the set and not worry about this issue.\n+            peer.m_headers_sync.reset(new HeadersSyncState(peer.m_id, m_chainparams.GetConsensus()));\n+            if (std::optional<CBlockLocator> locator =\n+                    peer.m_headers_sync->StartInitialDownload(chain_start_header,\n+                        headers, minimum_chain_work,\n+                        m_chainman.ActiveChain().GetLocator(chain_start_header)))\n+            {\n+                Assume(!locator->vHave.empty());\n+                if (!locator->vHave.empty() && MaybeSendGetHeaders(pfrom, *locator, peer)) {\n+                    LogPrint(BCLog::NET, \"more getheaders (from %s) to end to peer=%d\\n\",",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939062349",
      "id" : 939062349,
      "in_reply_to_id" : 938967065,
      "line" : 2465,
      "node_id" : "PRRC_kwDOABII5843-PRN",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 2458,
      "original_position" : 184,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 184,
      "pull_request_review_id" : 1063715336,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939062349/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T18:19:50Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939062349",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939436270"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939436270"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Just to make sure I understand your question -- I think you're wondering why this log message appears here as well as in `net_processing.cpp` at line 2473?\r\n\r\nThe issue is that in `net_processing` we won't bother even starting a headers sync using the logic in `headerssync.cpp` if we receive a headers message that (a) isn't full and (b) which connects to something we know in our block index and (c) has too little work, because we know in this case that the headers don't lead to a high work chain (if it did, the headers message would have been full, indicating the peer has more to give us).\r\n\r\nHowever, in the case that we start a headers sync using this module, then `net_processing` will be receiving headers that don't connect to the block index, and those messages can only be properly processed by this logic which keeps track of where we expect the headers to connect. So in this logic we also are checking whether the sync has to end because our peer has no more headers to give us (ie the headers message we processed from them was not full, and the chain has too little work).",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-05T22:58:22Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939436270",
      "id" : 939436270,
      "in_reply_to_id" : 938963599,
      "line" : 109,
      "node_id" : "PRRC_kwDOABII5843_qju",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 110,
      "original_position" : 110,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 110,
      "pull_request_review_id" : 1064220561,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939436270/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-05T22:58:22Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939436270",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939507811"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939507811"
         }
      },
      "author_association" : "MEMBER",
      "body" : "That was indeed my question.\r\n\r\nThe other confusing bit is the comment \"and definitely doesn't have enough work\". When looking at this function in isolation, it's not obvious why this would be the case, since we don't even check the work. It's also not obvious if I look at where this is called from.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T09:28:55Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939507811",
      "id" : 939507811,
      "in_reply_to_id" : 938963599,
      "line" : 109,
      "node_id" : "PRRC_kwDOABII5843_8Bj",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 110,
      "original_position" : 110,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 110,
      "pull_request_review_id" : 1064290130,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939507811/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T18:24:42Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939507811",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939523672"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939523672"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: maybe add additional tests where you set `minimumchainwork` to the chainwork at the original checkpoint (`0x0000000000000000000000000000000000000000000000000000022302230223`).\r\n\r\n```python\r\n\r\n        self.log.info(\"Feed all fork headers (fails due to minimum chain work)\")\r\n        # Disable checkpoint, but require its chainwork as the minimum.\r\n        self.restart_node(0, extra_args=['-nocheckpoints', \"-minimumchainwork=0x0000000000000000000000000000000000000000000000000000022302230223\"])\r\n        peer_minimumchainwork = self.nodes[0].add_p2p_connection(P2PInterface())\r\n        peer_minimumchainwork.send_and_ping(msg_headers(self.headers_fork))\r\n        with self.nodes[0].assert_debug_log(['Ignoring low-work chain']):\r\n            peer_minimumchainwork.send_message(msg_headers(self.headers_fork))\r\n            # We don't disconnect\r\n```\r\n\r\nNote that if you also set the minimum chainwork for node 0 for the entire test, it will stall at \"Feed all fork headers (fails due to checkpoint)\", because we no longer disconnect.\r\n\r\nNot sure if the above covers more ground than the new test file introduced in 7be81ce6257b1940d633b1311432c09fbbe09a0b, but it might still be useful to illustrate the behavior change. Then again, in the real world our minimum chainwork is much higher than that of the most recent checkpoints, so this example may be more confusing than illustrating? ",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T12:32:20Z",
      "diff_hunk" : "@@ -62,7 +63,7 @@ def run_test(self):\n \n         self.log.info(\"Feed all fork headers (succeeds without checkpoint)\")\n         # On node 0 it succeeds because checkpoints are disabled\n-        self.restart_node(0, extra_args=['-nocheckpoints'])\n+        self.restart_node(0, extra_args=['-nocheckpoints', \"-minimumchainwork=0x0\"])",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939523672",
      "id" : 939523672,
      "line" : 66,
      "node_id" : "PRRC_kwDOABII5843__5Y",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 66,
      "original_position" : 13,
      "original_start_line" : null,
      "path" : "test/functional/p2p_dos_header_tree.py",
      "position" : 13,
      "pull_request_review_id" : 1064303425,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939523672/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T12:55:26Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939523672",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939526940"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939526940"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: I was a bit surprised this never triggered an unused variable warning, but that's apparently possible with non-trivial types: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55203",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T13:09:16Z",
      "diff_hunk" : "@@ -2457,18 +2621,54 @@ void PeerManagerImpl::ProcessHeadersMessage(CNode& pfrom, Peer& peer,\n                                             const std::vector<CBlockHeader>& headers,\n                                             bool via_compact_block)\n {\n-    const CNetMsgMaker msgMaker(pfrom.GetCommonVersion());",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939526940",
      "id" : 939526940,
      "line" : 2460,
      "node_id" : "PRRC_kwDOABII5844AAsc",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 2460,
      "original_position" : 209,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 209,
      "pull_request_review_id" : 1064306189,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939526940/reactions"
      },
      "side" : "LEFT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T13:26:29Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939526940",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939557140"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939557140"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: I assume we're interested in those, because although their total work is lower, there's a chance a miner builds on top of it. In that case, if we receive only that new block (header), we already have the parent? Otherwise we'd need a peer to send multiple headers to learn about this new block.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T18:04:21Z",
      "diff_hunk" : "@@ -2256,6 +2297,35 @@ void PeerManagerImpl::SendBlockTransactions(CNode& pfrom, Peer& peer, const CBlo\n     m_connman.PushMessage(&pfrom, msgMaker.Make(NetMsgType::BLOCKTXN, resp));\n }\n \n+bool PeerManagerImpl::CheckHeadersPoW(const std::vector<CBlockHeader>& headers, const Consensus::Params& consensusParams, Peer& peer)\n+{\n+    // Do these headers have proof-of-work matching what's claimed?\n+    if (!HasValidProofOfWork(headers, consensusParams)) {\n+        Misbehaving(peer, 100, \"header with invalid proof of work\");\n+        return false;\n+    }\n+\n+    // Are these headers connected to each other?\n+    if (!CheckHeadersAreContinuous(headers)) {\n+        Misbehaving(peer, 20, \"non-continuous headers sequence\");\n+        return false;\n+    }\n+    return true;\n+}\n+\n+arith_uint256 PeerManagerImpl::GetAntiDoSWorkThreshold()\n+{\n+    arith_uint256 near_chaintip_work = 0;\n+    LOCK(cs_main);\n+    if (m_chainman.ActiveChain().Tip() != nullptr) {\n+        const CBlockIndex *tip = m_chainman.ActiveChain().Tip();\n+        // Use a 144 block buffer, so that we'll accept headers that fork from\n+        // near our tip.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939557140",
      "id" : 939557140,
      "line" : 2330,
      "node_id" : "PRRC_kwDOABII5844AIEU",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 2323,
      "original_position" : 95,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 95,
      "pull_request_review_id" : 1064330845,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939557140/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T18:05:05Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939557140",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939559072"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559072"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Oh, `ValidateAndStoreHeadersCommitments()` has the side-effect of changing `m_download_state` to `REDOWNLOAD` once minimum difficulty is reached.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T18:26:44Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939559072",
      "id" : 939559072,
      "in_reply_to_id" : 938963599,
      "line" : 109,
      "node_id" : "PRRC_kwDOABII5844AIig",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 110,
      "original_position" : 110,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 110,
      "pull_request_review_id" : 1064332485,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559072/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T18:26:56Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559072",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939559233"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559233"
         }
      },
      "author_association" : "MEMBER",
      "body" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d: maybe add a comment \"m_download_state is updated to REDOWNLOAD if headers reach the minimum difficulty.\"",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-06T18:28:36Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r939559233",
      "id" : 939559233,
      "line" : 93,
      "node_id" : "PRRC_kwDOABII5844AIlB",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 94,
      "original_position" : 94,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 94,
      "pull_request_review_id" : 1064332620,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559233/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-06T18:28:36Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/939559233",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "This subject reminds me of the \"Chain Width Expansion\" attack described in https://bcoin.io/papers/bitcoin-chain-expansion.pdf \r\n\r\nbitcoin-dev thread: https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-October/017354.html\r\n\r\nIn this paper the author suggested a solution (section 4.3) using proof-of-work to limit the rate of downloading headers (as well as pruning alternate header chain branches aka \"chain width\").\r\n\r\nI wonder how this strategy compares to the double-download strategy in this PR. They might be close in total elapsed time (slow downloading vs. downloading twice) but would obviously save on bandwidth.\r\n\r\nConceptually I love the idea of replacing hard-coded checkpoints, I'm just curious how this alternate solution measures up.",
      "created_at" : "2022-08-07T13:05:27Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1207404500",
      "id" : 1207404500,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585H94fU",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207404500/reactions"
      },
      "updated_at" : "2022-08-07T13:06:46Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207404500",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/2084648?v=4",
         "events_url" : "https://api.github.com/users/pinheadmz/events{/privacy}",
         "followers_url" : "https://api.github.com/users/pinheadmz/followers",
         "following_url" : "https://api.github.com/users/pinheadmz/following{/other_user}",
         "gists_url" : "https://api.github.com/users/pinheadmz/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/pinheadmz",
         "id" : 2084648,
         "login" : "pinheadmz",
         "node_id" : "MDQ6VXNlcjIwODQ2NDg=",
         "organizations_url" : "https://api.github.com/users/pinheadmz/orgs",
         "received_events_url" : "https://api.github.com/users/pinheadmz/received_events",
         "repos_url" : "https://api.github.com/users/pinheadmz/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/pinheadmz/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/pinheadmz/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/pinheadmz"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@pinheadmz  of the three attack scenarios in the paper, 1.3 is prevented because we ignore unsolicited blocks with less work than the tip (see [p2p_unrequested_blocks.py](https://github.com/bitcoin/bitcoin/blob/master/test/functional/p2p_unrequested_blocks.py#L22-L24)). The paper also points this out in (2). So the two attacks to worry about are 1.1 and 1.2. If you can solve 1.2 without the use of checkpoints, then 1.1 is automatically solved.\r\n\r\nSo the comparison boils down to: how does this PR stack up against the proposal in the paper in fixing 1.2.\r\n\r\nSpecifically the solutions we're looking at are 4.2 and 4.3 in the paper, since 4.1 (headers-first sync) is already implemented.\r\n\r\nNote that bandwidth for headers is only a fraction of bandwidth for blocks. All things equal less bandwidth is better, but it's not a huge factor on its own when comparing the approaches.\r\n\r\nThe same goes for elapsed time. Downloading headers takes only a fraction of the time of downloading blocks.\r\n\r\nAlso, because we can receive headers unsolicited, the amount of time and bandwidth we spend downloading useless headers is somewhat out of our control (rate limiting based on PoW could help though, see my comment on 4.3).\r\n\r\nI think there's two metrics we should care about, given an ongoing spam attack and a single honest node whispering the truth:\r\n1. how long does it take until we know enough to go ahead and download the corresponding blocks\r\n2. how much of disk space gets wasted with spam headers (and can we prune that before it becomes a serious problem)\r\n\r\nOne meta issue is that afaik there's no Bitcoin Core pull request of 4.1 and 4.2 from the paper, so that works in favor of this PR which does have working code (from a [rfc7282](https://www.rfc-editor.org/rfc/rfc7282) point of view). But the paper states there _is_ an implementation for Bcoin, so this is not a strong argument against. What do we know of how these implementations work in practice?\r\n\r\nWith all that out the way, how do the proposals 4.2 and 4.3 from the paper actually compare to this PR?\r\n\r\n4.2 suggests picking a maximum number of header chains to store, before pruning the shortest. It suggests storing 10 chains for a total of 480MB.\r\na) that's far more memory use than this PR requires (~700 KiB per peer, regardless of the amount of spam fired at us)\r\nb) In terms of bandwidth, under nice circumstances the approach uses less bandwidth, because headers are only downloaded once. But under attack circumstance most of the bandwidth is spent on downloading spam headers, in which case the redownload of correct headers is negligible. That goes for 4.2 as well as this PR.\r\nc) I'm not sure how the proposal holds up in a timewarp attack; I suppose it could perform the sane initial sanity checks on all header chains, e.g. checking the difficulty adjustment is allowed. Dealing with a timewarp attack is important because it would dramatically increase the space needed to store a header chain.\r\n\r\n4.3 Rate limiting header requests: I'm not sure how to evaluate that (others on the mailinglist also expressed difficulty with that). I do notice the paper points to advantages for CPU use, but I'm more worried about storage. I'm also not sure if this approach would put an \"honest\" massive reorg (by alien attacker) at an unfair disadvantage, e.g.  if said reorg started with lots of low difficulty blocks. But I guess eventually we'd find it.",
      "created_at" : "2022-08-08T08:36:32Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1207831433",
      "id" : 1207831433,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585H_guJ",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207831433/reactions"
      },
      "updated_at" : "2022-08-08T08:39:24Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207831433",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "> But the paper states there is an implementation for Bcoin [â¦] What do we know of how these implementations work in practice?\r\n\r\nFound the Bcoin client implementation, with the rate limiting part in https://github.com/bcoin-org/bcoin/commit/cf9d364d6a9424b9f4146bd620d43034af43b056. Unfortunately there hasn't been any review on it, and it's unmerged, so we don't have data on how this performs in practice.\r\n",
      "created_at" : "2022-08-08T10:19:29Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1207936111",
      "id" : 1207936111,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585H_6Rv",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207936111/reactions"
      },
      "updated_at" : "2022-08-08T10:19:29Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1207936111",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940092129"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940092129"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Maybe rename to `PopHeadersReadyForAcceptance()`",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-08T10:40:53Z",
      "diff_hunk" : "@@ -0,0 +1,332 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <pow.h>\n+#include <timedata.h>\n+#include <util/check.h>\n+\n+//! Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY{571};\n+\n+//! Only feed headers to validation once this many commitment bits on top have been checked.\n+//! During redownloading, a per-peer buffer with space for\n+//! HEADER_COMMITMENT_FREQUENCY * REDOWNLOAD_HEADERS_CHECK_BITS headers will be used.\n+constexpr size_t REDOWNLOAD_HEADERS_CHECK_BITS{25};\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+/** Free any memory in use, and mark this object as no longer usable. This is\n+ * required to guarantee that we won't reuse this object with the same\n+ * SaltedTxidHasher for another sync. */\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+    std::vector<uint256>().swap(m_chain_start_locator.vHave);\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+/** Initialize the parameters for this headers download, validate this first\n+ * batch, and request more headers. */\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::UNSTARTED);\n+    m_download_state = State::INITIAL_DOWNLOAD;\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    m_last_header_received = m_chain_start->GetBlockHeader();\n+\n+    // Estimate the number of blocks that could possibly exist on the peer's\n+    // chain *right now* using 6 blocks/second (fastest blockrate given the MTP\n+    // rule) times the number of seconds from the last allowed block until\n+    // today. This serves as a memory bound on how many commitments we might\n+    // store from this peer, and we can safely give up syncing if the peer\n+    // exceeds this bound, because it's not possible for a consensus-valid\n+    // chain to be longer than this (at the current time -- in the future we\n+    // could try again, if necessary, to sync a longer chain).\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+/** Process the next batch of headers received from our peer.\n+ *  Validate and store commitments, and compare total chainwork to our target to\n+ *  see if we can switch to REDOWNLOAD mode.  */\n+HeadersSyncState::ProcessingResult HeadersSyncState::ProcessNextHeaders(const\n+        std::vector<CBlockHeader>& headers, const bool full_headers_message)\n+{\n+    ProcessingResult ret;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return ret;\n+        }\n+        ret.success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            LogPrint(BCLog::NET, \"Ignoring low-work chain (height=%u) from peer=%d\\n\", m_current_height, m_id);\n+            Finalize();\n+            return ret;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return ret;\n+            }\n+        }\n+\n+        ret.success = true;\n+        // Return any headers that are ready for acceptance.\n+        ret.headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return ret;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            ret.locator = MakeNextHeadersRequest();\n+            return ret;\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return ret;\n+        }\n+    }\n+    return ret;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Somehow our peer gave us a header that doesn't connect.\n+        // This might be benign -- perhaps we issued an extra getheaders\n+        // message, such as after a block INV was received.\n+        // Or it could be that our peer is broken or malicious. If broken,\n+        // sending a new getheaders immediately could trigger an infinite\n+        // loop. Just give up for now; if our peer ever gives us an block\n+        // INV later we will fetch headers then, and likely retrigger this\n+        // logic.\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash = m_chain_start->GetBlockHash();\n+        m_redownload_chain_work = m_chain_start->nChainWork;\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // It's possible the chain grew since we started the sync; so\n+            // potentially we could succeed in syncing the peer's chain if we\n+            // try again later.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // Check that the difficulty adjustments are within our tolerance:\n+    uint32_t previous_nBits{0};\n+    if (!m_redownloaded_headers.empty()) {\n+        previous_nBits = m_redownloaded_headers.back().nBits;\n+    } else {\n+        previous_nBits = m_chain_start->nBits;\n+    }\n+\n+    if (!PermittedDifficultyTransition(m_consensus_params, next_height,\n+                previous_nBits, header.nBits)) {\n+        return false;\n+    }\n+\n+    // Track work on the redownloaded chain\n+    m_redownload_chain_work += GetBlockProof(CBlockIndex(header));\n+\n+    if (m_redownload_chain_work >= m_minimum_required_work) {\n+        m_process_all_remaining_headers = true;\n+    }\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    // Also, don't check commitments once we've gotten to our target blockhash;\n+    // it's possible our peer has extended its chain between our first sync and\n+    // our second, and we don't want to return failure after we've seen our\n+    // target blockhash just because we ran out of commitments.\n+    if (!m_process_all_remaining_headers && (next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    return true;\n+}\n+\n+std::vector<CBlockHeader> HeadersSyncState::RemoveHeadersReadyForAcceptance()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940092129",
      "id" : 940092129,
      "line" : 294,
      "node_id" : "PRRC_kwDOABII5844CKrh",
      "original_commit_id" : "caa2419e65e3b9d7183f2246d66eb7ce6b7ce1f7",
      "original_line" : 294,
      "original_position" : 294,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 294,
      "pull_request_review_id" : 1064970764,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940092129/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-08T11:40:08Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940092129",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940093835"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940093835"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Passing headers in and out of this function is a bit hard to follow. I think we need a more descriptive term than \"process\" and \"to process\". You could rename the input `headers` to `received_headers` and the return value `headers_to_process` with `pow_checked_headers` or `filtered_headers`.\r\n\r\nBut perhaps it's even more clear if you decouple the feeding of headers into `HeadersSyncState` from the step of extracting filtered headers. Though I suppose these do have to happen in lock step.",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-08T10:43:00Z",
      "diff_hunk" : "@@ -0,0 +1,255 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <arith_uint256.h>\n+#include <chain.h>\n+#include <consensus/params.h>\n+#include <net.h> // For NodeId\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <util/bitdeque.h>\n+#include <util/hasher.h>\n+\n+#include <deque>\n+#include <vector>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer and only accept headers\n+ * from that buffer into the block index (permanent memory usage) once they\n+ * have some target number of verified commitments on top of them. With this\n+ * parametrization, we can achieve a given security target for potential\n+ * permanent memory usage, while choosing N to minimize memory use during the\n+ * sync (temporary, per-peer storage).\n+ */\n+\n+class HeadersSyncState {\n+public:\n+    HeadersSyncState(NodeId id, const Consensus::Params& consensus_params);\n+    ~HeadersSyncState() {}\n+\n+    enum class State {\n+        UNSTARTED,\n+        /** INITIAL_DOWNLOAD means the peer has not yet demonstrated their\n+         * chain has sufficient work */\n+        INITIAL_DOWNLOAD,\n+        /** REDOWNLOAD means the peer has given us a high-enough-work chain,\n+         * and now we're redownloading the headers we saw before and trying to\n+         * accept them */\n+        REDOWNLOAD,\n+        /** We're done syncing with this peer and can discard any remaining state */\n+        FINAL\n+    };\n+\n+    /** Return the current state of our download */\n+    State GetState() const { return m_download_state; }\n+\n+    /** Start headers sync (via this download-twice mechanism)\n+     * chain_start: best known fork point that the peer's headers branch from\n+     * initial_headers: first batch of headers to process (assumes the caller\n+     *                  has already verified the headers connect)\n+     * minimum_required_work: amount of chain work required to accept the chain\n+     */\n+    std::optional<CBlockLocator> StartInitialDownload(const CBlockIndex* chain_start, const\n+            std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+            minimum_required_work, CBlockLocator&& chain_start_locator);\n+\n+    struct ProcessingResult {\n+        std::optional<CBlockLocator> locator{std::nullopt};\n+        std::vector<CBlockHeader> headers_to_process;\n+        bool success{false};\n+    };\n+\n+    /** Process a batch of headers, once a sync via this mechanism has started\n+     *\n+     * headers: headers that were received over the network for processing.\n+     *          Assumes the caller has already verified the headers connect.\n+     * full_headers_message: true if the message was at max capacity,\n+     *                       indicating more headers may be available\n+     * ProcessingResult.headers_to_process: will be filled in with any headers that the caller\n+     *                       can process and validate now (because these returned\n+     *                       headers are on a chain with sufficient work)\n+     * ProcessingResult.success: set to false if an error is detected and the sync is\n+     *                       aborted; true otherwise.\n+     * ProcessingResult.locator: if present, the next locator to send in a\n+     *                       getheaders message\n+     */\n+    ProcessingResult ProcessNextHeaders(const std::vector<CBlockHeader>&",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940093835",
      "id" : 940093835,
      "line" : 152,
      "node_id" : "PRRC_kwDOABII5844CLGL",
      "original_commit_id" : "caa2419e65e3b9d7183f2246d66eb7ce6b7ce1f7",
      "original_line" : 152,
      "original_position" : 152,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : 152,
      "pull_request_review_id" : 1064970764,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940093835/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-08T11:40:08Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940093835",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940138850"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940138850"
         }
      },
      "author_association" : "MEMBER",
      "body" : "2444ce2f8cb1330ba1dc88b7e5407a3efcfd9aeb The above `MaybeSendPing` and `MaybeSendAddr`  suggests we should put this in a helper function `MaybeSendSendHeaders()`",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-08T11:38:37Z",
      "diff_hunk" : "@@ -5076,6 +5072,24 @@ bool PeerManagerImpl::SendMessages(CNode* pto)\n \n     MaybeSendAddr(*pto, *peer, current_time);\n \n+    // Delay sending SENDHEADERS (BIP 130) until we're done with an\n+    // initial-headers-sync with this peer. Receiving headers announcements for\n+    // new blocks while trying to sync their headers chain is problematic,\n+    // because of the state tracking done.\n+    if (!peer->m_sent_sendheaders && pto->GetCommonVersion() >= SENDHEADERS_VERSION) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940138850",
      "id" : 940138850,
      "line" : 5079,
      "node_id" : "PRRC_kwDOABII5844CWFi",
      "original_commit_id" : "2444ce2f8cb1330ba1dc88b7e5407a3efcfd9aeb",
      "original_line" : 5079,
      "original_position" : 32,
      "original_start_line" : null,
      "path" : "src/net_processing.cpp",
      "position" : 32,
      "pull_request_review_id" : 1064970764,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940138850/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-08T11:40:08Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940138850",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940153281"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940153281"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Do we need to rethink our headers sync timeout and/or disconnect logic? What happens when the first peer we try to do a headers sync with sends a low work chain? Since we don't disconnect, is there another mechanism that causes us to try with another peer, or do we wait for a timeout or new block announcement? (trying to figure this out from just reading `net_processing.cpp` is daunting...)",
      "commit_id" : "6ef78a8af3c9cec7f877f9cca9fc761d472134bf",
      "created_at" : "2022-08-08T11:56:40Z",
      "diff_hunk" : "@@ -62,7 +63,7 @@ def run_test(self):\n \n         self.log.info(\"Feed all fork headers (succeeds without checkpoint)\")\n         # On node 0 it succeeds because checkpoints are disabled\n-        self.restart_node(0, extra_args=['-nocheckpoints'])\n+        self.restart_node(0, extra_args=['-nocheckpoints', \"-minimumchainwork=0x0\"])",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r940153281",
      "id" : 940153281,
      "in_reply_to_id" : 939523672,
      "line" : 66,
      "node_id" : "PRRC_kwDOABII5844CZnB",
      "original_commit_id" : "5691c174c5cb2f9947e6cc2db8d32b4b4715e47d",
      "original_line" : 66,
      "original_position" : 13,
      "original_start_line" : null,
      "path" : "test/functional/p2p_dos_header_tree.py",
      "position" : 13,
      "pull_request_review_id" : 1065056740,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940153281/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-08-08T11:57:19Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/940153281",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/10217?v=4",
         "events_url" : "https://api.github.com/users/Sjors/events{/privacy}",
         "followers_url" : "https://api.github.com/users/Sjors/followers",
         "following_url" : "https://api.github.com/users/Sjors/following{/other_user}",
         "gists_url" : "https://api.github.com/users/Sjors/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/Sjors",
         "id" : 10217,
         "login" : "Sjors",
         "node_id" : "MDQ6VXNlcjEwMjE3",
         "organizations_url" : "https://api.github.com/users/Sjors/orgs",
         "received_events_url" : "https://api.github.com/users/Sjors/received_events",
         "repos_url" : "https://api.github.com/users/Sjors/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/Sjors/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/Sjors/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/Sjors"
      }
   }
]
