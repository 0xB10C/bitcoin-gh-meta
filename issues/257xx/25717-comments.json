[
   {
      "author_association" : "MEMBER",
      "body" : "Concept ACK, will review soon",
      "created_at" : "2022-07-26T23:32:30Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196096355",
      "id" : 1196096355,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HSvtj",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196096355/reactions"
      },
      "updated_at" : "2022-07-26T23:32:30Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196096355",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/73197?v=4",
         "events_url" : "https://api.github.com/users/jamesob/events{/privacy}",
         "followers_url" : "https://api.github.com/users/jamesob/followers",
         "following_url" : "https://api.github.com/users/jamesob/following{/other_user}",
         "gists_url" : "https://api.github.com/users/jamesob/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/jamesob",
         "id" : 73197,
         "login" : "jamesob",
         "node_id" : "MDQ6VXNlcjczMTk3",
         "organizations_url" : "https://api.github.com/users/jamesob/orgs",
         "received_events_url" : "https://api.github.com/users/jamesob/received_events",
         "repos_url" : "https://api.github.com/users/jamesob/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/jamesob/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/jamesob/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/jamesob"
      }
   },
   {
      "author_association" : "CONTRIBUTOR",
      "body" : "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#24571](https://github.com/bitcoin/bitcoin/pull/24571) (p2p: Prevent block index fingerprinting by sending additional getheaders messages by dergoegge)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.",
      "created_at" : "2022-07-27T06:03:31Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196300260",
      "id" : 1196300260,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HThfk",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196300260/reactions"
      },
      "updated_at" : "2022-07-27T06:03:31Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196300260",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/39886733?v=4",
         "events_url" : "https://api.github.com/users/DrahtBot/events{/privacy}",
         "followers_url" : "https://api.github.com/users/DrahtBot/followers",
         "following_url" : "https://api.github.com/users/DrahtBot/following{/other_user}",
         "gists_url" : "https://api.github.com/users/DrahtBot/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/DrahtBot",
         "id" : 39886733,
         "login" : "DrahtBot",
         "node_id" : "MDQ6VXNlcjM5ODg2NzMz",
         "organizations_url" : "https://api.github.com/users/DrahtBot/orgs",
         "received_events_url" : "https://api.github.com/users/DrahtBot/received_events",
         "repos_url" : "https://api.github.com/users/DrahtBot/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/DrahtBot/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/DrahtBot/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/DrahtBot"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "It's worth pointing out that initial headers sync will be slowed down by this PR, not just because we will download headers twice before storing, but also because the additional latency to make progress on syncing with our initial headers-sync-peer will mean that we're more likely to receive a block announcement while waiting for headers sync to finish, which in turn will trigger a headers sync with all our peers that announce the block. (And our starting point for those syncs will be further behind, because we don't make progress on adding headers to our block index until phase 2.)\r\n\r\nI opened #25720 as a mitigation for this effect; many strategies are possible and I think they are orthogonal to the change proposed here, so I'd prefer to leave the discussion of this particular issue to that PR.",
      "created_at" : "2022-07-27T15:59:13Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1196948065",
      "id" : 1196948065,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HV_ph",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196948065/reactions"
      },
      "updated_at" : "2022-07-27T15:59:13Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1196948065",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/7463573?v=4",
         "events_url" : "https://api.github.com/users/sdaftuar/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sdaftuar/followers",
         "following_url" : "https://api.github.com/users/sdaftuar/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sdaftuar/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sdaftuar",
         "id" : 7463573,
         "login" : "sdaftuar",
         "node_id" : "MDQ6VXNlcjc0NjM1NzM=",
         "organizations_url" : "https://api.github.com/users/sdaftuar/orgs",
         "received_events_url" : "https://api.github.com/users/sdaftuar/received_events",
         "repos_url" : "https://api.github.com/users/sdaftuar/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sdaftuar/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sdaftuar"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "This seems to be based on the assumption that the DoS is attacking disk space, but bandwidth tends to be more limited than space, and it makes that worse even in the best scenario...?",
      "created_at" : "2022-07-27T19:53:09Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197297765",
      "id" : 1197297765,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXVBl",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197297765/reactions"
      },
      "updated_at" : "2022-07-27T19:53:09Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197297765",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/1095675?v=4",
         "events_url" : "https://api.github.com/users/luke-jr/events{/privacy}",
         "followers_url" : "https://api.github.com/users/luke-jr/followers",
         "following_url" : "https://api.github.com/users/luke-jr/following{/other_user}",
         "gists_url" : "https://api.github.com/users/luke-jr/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/luke-jr",
         "id" : 1095675,
         "login" : "luke-jr",
         "node_id" : "MDQ6VXNlcjEwOTU2NzU=",
         "organizations_url" : "https://api.github.com/users/luke-jr/orgs",
         "received_events_url" : "https://api.github.com/users/luke-jr/received_events",
         "repos_url" : "https://api.github.com/users/luke-jr/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/luke-jr/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/luke-jr/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/luke-jr"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@luke-jr The DoS concern is primarily about memory usage: filling mapBlockIndex and other data structures with low-difficulty headers before a checkpoint is reached.\r\n\r\nBandwidth is a concern for sure, but:\r\n* There are many more effective ways to perform bandwidth DoS (like spamming INV messages, ADDR messages, PING messages, continuously requesting non-existing transactions or blocks, ...).\r\n* The proper solution to bandwidth DoS is just throttling peers that waste too much of it.\r\n* In non-attack scenarios, the added bandwidth by this PR (especially when combined with #25720) is in the order of 10s of MB over a node's lifetime, which is negligible compared to the full block download.\r\n",
      "created_at" : "2022-07-27T20:24:19Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197328410",
      "id" : 1197328410,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXcga",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 1,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 1,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197328410/reactions"
      },
      "updated_at" : "2022-07-27T20:24:42Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197328410",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Is there a reason to not just prune the block index under some conditions?",
      "created_at" : "2022-07-27T20:33:17Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197336868",
      "id" : 1197336868,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXekk",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197336868/reactions"
      },
      "updated_at" : "2022-07-27T20:33:17Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197336868",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/1095675?v=4",
         "events_url" : "https://api.github.com/users/luke-jr/events{/privacy}",
         "followers_url" : "https://api.github.com/users/luke-jr/followers",
         "following_url" : "https://api.github.com/users/luke-jr/following{/other_user}",
         "gists_url" : "https://api.github.com/users/luke-jr/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/luke-jr",
         "id" : 1095675,
         "login" : "luke-jr",
         "node_id" : "MDQ6VXNlcjEwOTU2NzU=",
         "organizations_url" : "https://api.github.com/users/luke-jr/orgs",
         "received_events_url" : "https://api.github.com/users/luke-jr/received_events",
         "repos_url" : "https://api.github.com/users/luke-jr/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/luke-jr/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/luke-jr/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/luke-jr"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "Here is the script to compute the optimal parameters used, with lots of explanation: https://gist.github.com/sipa/016ae445c132cdf65a2791534dfb7ae1 (it takes around 20s for me in `pypy3`, though over 2 minutes in `python3`).\r\n\r\nIt may make sense to include the script in the repository (as I can imagine it being re-run to tune things occasionally, but there should not be a need to do it more than every few years). It could also live on the devwiki or just linked-to in the code. Opinions?\r\n\r\n",
      "created_at" : "2022-07-27T21:14:13Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197375266",
      "id" : 1197375266,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HXn8i",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197375266/reactions"
      },
      "updated_at" : "2022-07-28T02:33:26Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197375266",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "@luke-jr I think that's a potentially useful but orthogonal improvement, though there is probably much less need for it after this PR.",
      "created_at" : "2022-07-27T22:29:56Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1197439146",
      "id" : 1197439146,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585HX3iq",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197439146/reactions"
      },
      "updated_at" : "2022-07-27T22:29:56Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1197439146",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932182732"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit: please sort these alphabetically",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:55:03Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932182732",
      "id" : 932182732,
      "line" : 18,
      "node_id" : "PRRC_kwDOABII5843j_rM",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 18,
      "original_position" : 18,
      "original_start_line" : 8,
      "path" : "src/headerssync.h",
      "position" : 18,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 8,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:32Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932182732",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932184020"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020"
         }
      },
      "author_association" : "MEMBER",
      "body" : "nit: please sort these alphabetically",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:56:16Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932184020",
      "id" : 932184020,
      "line" : 5,
      "node_id" : "PRRC_kwDOABII5843j__U",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 5,
      "original_position" : 5,
      "original_start_line" : 1,
      "path" : "src/headerssync.cpp",
      "position" : 5,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 1,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932184020",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932186749"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Why not do that in this PR? Maybe add a new state `FAILED` (or an extra bool on `HeadersSyncState`) that signals to `net_processing` that the peer should be disconnected? That seems simple enough and in obvious cases like this one (i.e. too many commitments or e.g. invalid PoW) the peer definitely behaved funky and should be punished.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T12:58:51Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932186749",
      "id" : 932186749,
      "line" : 220,
      "node_id" : "PRRC_kwDOABII5843kAp9",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 220,
      "original_position" : 220,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 220,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932186749",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932235084"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Add function to validate difficulty changes\":\r\n\r\nI realize this is mostly-copied code, but can you follow the style guide here (braces when the then statement isn't on the same line)?\r\n\r\n(here and below)",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:42:00Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);\n+        arith_uint256 observed_new_target;\n+        observed_new_target.SetCompact(new_nbits);\n+\n+        // Calculate the largest difficulty value possible:\n+        arith_uint256 bnNew;\n+        bnNew.SetCompact(old_nbits);\n+        bnNew *= largest_timespan;\n+        bnNew /= params.nPowTargetTimespan;\n+\n+        if (bnNew > bnPowLimit)\n+            bnNew = bnPowLimit;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932235084",
      "id" : 932235084,
      "line" : 95,
      "node_id" : "PRRC_kwDOABII5843kMdM",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 95,
      "original_position" : 25,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 25,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932235084",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932238513"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Utilize anti-DoS headers download strategy\":\r\n\r\nPerhaps use doxygen comments for comments on a function/variable definition or declaration? (either `/** ... */` or `//! ...`). That way they get picked up by doxygen for generating documentation.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:45:03Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932238513",
      "id" : 932238513,
      "line" : 7,
      "node_id" : "PRRC_kwDOABII5843kNSx",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 7,
      "original_position" : 7,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 7,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932238513",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932252053"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Maybe also wipe `m_chain_start_locator`?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T13:56:14Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932252053",
      "id" : 932252053,
      "line" : 24,
      "node_id" : "PRRC_kwDOABII5843kQmV",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 24,
      "original_position" : 24,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 24,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932252053",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932256694"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nPerhaps document that this is required to guarantee that the object isn't reused with the same SaltedTxidHasher for another sync attempt.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:00:08Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932256694",
      "id" : 932256694,
      "line" : 23,
      "node_id" : "PRRC_kwDOABII5843kRu2",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 23,
      "original_position" : 23,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 23,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932256694",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932259718"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nArguably, it's not exactly true that no consensus-valid chain can be longer, but it's not possible for the peer to have such a chain at the time the sync starts (it'd need a tip timestamp that is in the future at the time the sync starts).",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:02:39Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932259718",
      "id" : 932259718,
      "line" : 61,
      "node_id" : "PRRC_kwDOABII5843kSeG",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 61,
      "original_position" : 61,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 61,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932259718",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932271718"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nAny reason to do this here, and not in `StartInitialDownload`? It seems a bit cleaner to set these values as soon as they're known, rather than on the fly.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:13:01Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932271718",
      "id" : 932271718,
      "line" : 168,
      "node_id" : "PRRC_kwDOABII5843kVZm",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 168,
      "original_position" : 168,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 168,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932271718",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932272722"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nShould there be a restriction to not call StartInitialDownload twice on the same object?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:13:52Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932272722",
      "id" : 932272722,
      "line" : 47,
      "node_id" : "PRRC_kwDOABII5843kVpS",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 47,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 47,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932272722",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932277428"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428"
         }
      },
      "author_association" : "MEMBER",
      "body" : "This only checks node 1.\r\n```suggestion\r\n        for node in self.nodes[1:]:\r\n            chaintips = node.getchaintips()\r\n            assert(len(chaintips) == 1)\r\n            assert {\r\n                'height': 0,\r\n                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\r\n                'branchlen': 0,\r\n                'status': 'active',\r\n            } in chaintips\r\n```",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:17:48Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932277428",
      "id" : 932277428,
      "line" : 39,
      "node_id" : "PRRC_kwDOABII5843kWy0",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 39,
      "original_position" : 39,
      "original_start_line" : 31,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 39,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 31,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932277428",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932278011"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nPerhaps document that we rely on the caller having verified that the headers are continuous (each has the previous one's hash as their prevhash)?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:18:19Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932278011",
      "id" : 932278011,
      "line" : 179,
      "node_id" : "PRRC_kwDOABII5843kW77",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 179,
      "original_position" : 179,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 179,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932278011",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281150"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think you could get rid of the `time.sleep` with `assert_debug_log`.\r\n```suggestion\r\n    with self.nodes[1].assert_debug_log(expected_msgs=[\"[net] Ignoring low-work chain\"]), self.nodes[2].assert_debug_log(expected_msgs=[\"[net] Ignoring low-work chain\"]):\r\n         self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\r\n```",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:21:05Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281150",
      "id" : 932281150,
      "line" : 30,
      "node_id" : "PRRC_kwDOABII5843kXs-",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 30,
      "original_position" : 30,
      "original_start_line" : 27,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 30,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150/reactions"
      },
      "side" : "RIGHT",
      "start_line" : 27,
      "start_side" : "RIGHT",
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281150",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281858"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Nit in \"Utilize anti-DoS headers download strategy\"\r\n\r\nWhy \"try\"? It doesn't look like the adding of a commitment can fail.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:21:42Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932281858",
      "id" : 932281858,
      "line" : 216,
      "node_id" : "PRRC_kwDOABII5843kX4C",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 216,
      "original_position" : 216,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 216,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:00Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932281858",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932282250"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250"
         }
      },
      "author_association" : "MEMBER",
      "body" : "node 0 and node 2 are not connected in this test but it looks like that is an assumption here?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:22:02Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932282250",
      "id" : 932282250,
      "line" : 29,
      "node_id" : "PRRC_kwDOABII5843kX-K",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 29,
      "original_position" : 29,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 29,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932282250",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932283353"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Why does `NODE1_BLOCKS_REQUIRED` match with the comment but `NODE2_BLOCKS_REQUIRED` doesn't?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:22:56Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932283353",
      "id" : 932283353,
      "line" : 19,
      "node_id" : "PRRC_kwDOABII5843kYPZ",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 19,
      "original_position" : 19,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 19,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932283353",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932286853"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853"
         }
      },
      "author_association" : "MEMBER",
      "body" : "I think this `time.sleep` is not needed given the `sync_blocks` call below?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:25:13Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932286853",
      "id" : 932286853,
      "line" : 43,
      "node_id" : "PRRC_kwDOABII5843kZGF",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 43,
      "original_position" : 43,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 43,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932286853",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932288256"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256"
         }
      },
      "author_association" : "MEMBER",
      "body" : "Could also use `assert_debug_log` like suggested above instead of the sleep.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:26:00Z",
      "diff_hunk" : "@@ -0,0 +1,68 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2019-2021 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Test that we reject low difficulty headers to prevent our block tree from filling up with useless bloat\"\"\"\n+\n+from test_framework.test_framework import BitcoinTestFramework\n+\n+import time\n+\n+NODE1_BLOCKS_REQUIRED = 16\n+NODE2_BLOCKS_REQUIRED = 2047\n+\n+\n+class RejectLowDifficultyHeadersTest(BitcoinTestFramework):\n+    def set_test_params(self):\n+        self.setup_clean_chain = True\n+        self.num_nodes = 3\n+        # Node0 has no required chainwork; node1 requires 16 blocks; node2 requires 2048 blocks\n+        self.extra_args = [[\"-minimumchainwork=0x0\"], [\"-minimumchainwork=0x1f\"], [\"-minimumchainwork=0x1000\"]]\n+\n+    def skip_test_if_missing_module(self):\n+        self.skip_if_no_wallet()\n+\n+    def test_chains_sync_when_long_enough(self):\n+        self.log.info(\"Generate blocks on the node with no required chainwork\")\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED-2, sync_fun=self.no_op)\n+\n+        self.log.info(\"Verify nodes 1 and 2 have no new headers in their headers tree\")\n+        time.sleep(2)\n+        for i in range(1, 2):\n+            chaintips = self.nodes[i].getchaintips()\n+            assert(len(chaintips) == 1)\n+            assert {\n+                'height': 0,\n+                'hash': '0f9188f13cb7b2c71f2a335e3a4fc328bf5beb436012afca590b1a11466e2206',\n+                'branchlen': 0,\n+                'status': 'active',\n+            } in chaintips\n+\n+        self.generate(self.nodes[0], NODE1_BLOCKS_REQUIRED - self.nodes[0].getblockcount(), sync_fun=self.no_op)\n+        self.log.info(\"Verify that node1 syncs node0's chain\")\n+        time.sleep(2)\n+        self.sync_blocks(self.nodes[0:2])\n+\n+        self.log.info(\"Verify that node2 still has no new headers\")\n+        time.sleep(2)",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932288256",
      "id" : 932288256,
      "line" : 47,
      "node_id" : "PRRC_kwDOABII5843kZcA",
      "original_commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "original_line" : 47,
      "original_position" : 47,
      "original_start_line" : null,
      "path" : "test/functional/p2p_headers_sync_with_minchainwork.py",
      "position" : 47,
      "pull_request_review_id" : 1054040362,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:41:33Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932288256",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/8077169?v=4",
         "events_url" : "https://api.github.com/users/dergoegge/events{/privacy}",
         "followers_url" : "https://api.github.com/users/dergoegge/followers",
         "following_url" : "https://api.github.com/users/dergoegge/following{/other_user}",
         "gists_url" : "https://api.github.com/users/dergoegge/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/dergoegge",
         "id" : 8077169,
         "login" : "dergoegge",
         "node_id" : "MDQ6VXNlcjgwNzcxNjk=",
         "organizations_url" : "https://api.github.com/users/dergoegge/orgs",
         "received_events_url" : "https://api.github.com/users/dergoegge/received_events",
         "repos_url" : "https://api.github.com/users/dergoegge/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/dergoegge/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/dergoegge/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/dergoegge"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932294356"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nJust a thought for later, but it's rather ugly to have to construct a `CBlockIndex` object just to be able to call `GetBlockProof`. I think `GetBlockProof` should work (or have a variant that works) with a `CBlockHeader` too, or even just the nBits value.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:29:34Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932294356",
      "id" : 932294356,
      "line" : 226,
      "node_id" : "PRRC_kwDOABII5843ka7U",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 226,
      "original_position" : 226,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 226,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932294356",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932300194"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nIs it possible to set this `m_redownload_buffer_last_hash = m_chain_start->GetBlockHash(); m_redownload_buffer_last_height = m_chain_start->nHeight;` in `ValidateAndStoreHeadersCommitments` already when the transition to REDOWNLOAD state is made?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:33:58Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932300194",
      "id" : 932300194,
      "line" : 241,
      "node_id" : "PRRC_kwDOABII5843kcWi",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 241,
      "original_position" : 241,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 241,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932300194",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932308150"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nCould there be a concern that the last or few last headers or so get reorganized during the second phase, resulting in a mismatch at the end? If so, perhaps it's possible to instead keep track of chainwork again in the second phase rather than remembering the exact hash at which the threshold was reached in the first phase?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:38:05Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932308150",
      "id" : 932308150,
      "line" : 272,
      "node_id" : "PRRC_kwDOABII5843keS2",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 272,
      "original_position" : 272,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 272,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932308150",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932322801"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\n`return CBlockLocator(std::move(locator))` saves a copy.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:46:36Z",
      "diff_hunk" : "@@ -0,0 +1,318 @@\n+#include <headerssync.h>\n+#include <logging.h>\n+#include <util/check.h>\n+#include <pow.h>\n+#include <timedata.h>\n+\n+// Store a commitment to a header every HEADER_COMMITMENT_FREQUENCY blocks\n+constexpr size_t HEADER_COMMITMENT_FREQUENCY = 571;\n+// Pull out headers for acceptance during redownload once our buffer exceeds this amount\n+constexpr size_t REDOWNLOAD_HEADERS_THRESHOLD = 25*HEADER_COMMITMENT_FREQUENCY;\n+// Ensure that the redownload buffer is a multiple of the header commitment\n+// frequency, so that we aren't wasting memory.\n+static_assert(REDOWNLOAD_HEADERS_THRESHOLD % HEADER_COMMITMENT_FREQUENCY == 0);\n+\n+// Our memory analysis assumes 48 bytes for a CompressedHeader (so we should\n+// re-calculate parameters if we compress further)\n+static_assert(sizeof(CompressedHeader) == 48);\n+\n+HeadersSyncState::HeadersSyncState(NodeId id, const Consensus::Params& consensus_params) :\n+    m_id(id), m_consensus_params(consensus_params)\n+{ }\n+\n+// Free any memory in use, and mark this object as no longer usable.\n+void HeadersSyncState::Finalize()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    m_header_commitments.clear();\n+    m_last_header_received.SetNull();\n+    m_blockhash_with_sufficient_work.SetNull();\n+    std::deque<CompressedHeader>().swap(m_redownloaded_headers);\n+    m_redownload_buffer_last_hash.SetNull();\n+    m_redownload_buffer_first_prev_hash.SetNull();\n+    m_process_all_remaining_headers = false;\n+    m_current_height = 0;\n+\n+    m_download_state = State::FINAL;\n+}\n+\n+// Initialize the parameters for this headers download, validate this first\n+// batch, and request more headers.\n+std::optional<CBlockLocator> HeadersSyncState::StartInitialDownload(const CBlockIndex* chain_start,\n+        const std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+        minimum_required_work, CBlockLocator&& chain_start_locator)\n+{\n+    // A new instance of this object should be instantiated for every headers\n+    // sync, so that we don't reuse our salted hasher between syncs.\n+    assert(m_download_state == State::INITIAL_DOWNLOAD);\n+\n+    m_chain_start = chain_start;\n+    m_minimum_required_work = minimum_required_work;\n+    m_current_chain_work = chain_start->nChainWork;\n+    m_current_height = chain_start->nHeight;\n+    m_chain_start_locator = std::move(chain_start_locator);\n+\n+    // Overestimate the number of blocks that could possibly exist on this\n+    // chain using 6 blocks/second (fastest blockrate given the MTP rule) times\n+    // the number of seconds from the last allowed block until today. This\n+    // serves as a memory bound on how many commitments we might store from\n+    // this peer, and we can safely give up syncing if the peer exceeds this\n+    // bound, because it's not possible for a consensus-valid chain to be\n+    // longer than this.\n+    m_max_commitments = 6*(GetAdjustedTime() - chain_start->GetMedianTimePast() + MAX_FUTURE_BLOCK_TIME) / HEADER_COMMITMENT_FREQUENCY;\n+\n+    if (!ValidateAndStoreHeadersCommitments(initial_headers)) {\n+        return std::nullopt;\n+    }\n+    return MakeNextHeadersRequest();\n+}\n+\n+// Process the next batch of headers received from our peer.\n+// Validate and store commitments, and compare total chainwork to our target to\n+// see if we can switch to REDOWNLOAD mode.\n+std::optional<CBlockLocator> HeadersSyncState::ProcessNextHeaders(const std::vector<CBlockHeader>&\n+        headers, bool full_headers_message, std::vector<CBlockHeader>&\n+        headers_to_process, bool& processing_success)\n+{\n+    processing_success = false;\n+\n+    Assume(!headers.empty());\n+    if (headers.empty()) return std::nullopt;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD) {\n+        // During INITIAL_DOWNLOAD, we minimally validate block headers and\n+        // occasionally add commitments to them, until we reach our work\n+        // threshold.\n+        if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+            // Somehow our peer gave us a header that doesn't connect.\n+            // This might be benign -- perhaps we issued an extra getheaders\n+            // message, such as after a block INV was received.\n+            // Or it could be that our peer is broken or malicious. If broken,\n+            // sending a new getheaders immediately could trigger an infinite\n+            // loop. Just give up for now; if our peer ever gives us an block\n+            // INV later we will fetch headers then, and likely retrigger this\n+            // logic.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+        if (!ValidateAndStoreHeadersCommitments(headers)) {\n+            // The headers didn't pass validation; give up on the sync.\n+            return std::nullopt;\n+        }\n+        processing_success = true;\n+        if (full_headers_message || m_download_state == State::REDOWNLOAD) {\n+            // A full headers message means the peer may have more to give us;\n+            // also if we just switched to REDOWNLOAD then we need to re-request\n+            // headers from the beginning.\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // If we're in INITIAL_DOWNLOAD and we get a non-full headers\n+            // message, then the peer's chain has ended and definitely doesn't\n+            // have enough work, so we can stop our sync.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    } else if (m_download_state == State::REDOWNLOAD) {\n+        // During REDOWNLOAD, we compare our stored commitments to what we\n+        // receive, and add headers to our redownload buffer. When the buffer\n+        // gets big enough (meaning that we've checked enough commitments),\n+        // we'll return a batch of headers to the caller for processing.\n+        for (const auto& hdr : headers) {\n+            if (!ValidateAndStoreRedownloadedHeader(hdr)) {\n+                // Something went wrong -- the peer gave us an unexpected chain.\n+                // We could consider looking at the reason for failure and\n+                // punishing the peer, but for now just give up on sync.\n+                Finalize();\n+                return std::nullopt;\n+            }\n+        }\n+\n+        processing_success = true;\n+        // Return any headers that are ready for acceptance.\n+        headers_to_process = RemoveHeadersReadyForAcceptance();\n+\n+        // If we hit our target blockhash, then all remaining headers will be\n+        // returned and we can clear any leftover internal state.\n+        if (m_redownloaded_headers.empty() && m_process_all_remaining_headers) {\n+            Finalize();\n+            return std::nullopt;\n+        }\n+\n+        // If the headers message is full, we need to request more.\n+        if (full_headers_message) {\n+            return MakeNextHeadersRequest();\n+        } else {\n+            // For some reason our peer gave us a high-work chain, but is now\n+            // declining to serve us that full chain again. Give up.\n+            // Note that there's no more processing to be done with these\n+            // headers, so we can still return success.\n+            Finalize();\n+            return std::nullopt;\n+        }\n+    }\n+    return std::nullopt;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreHeadersCommitments(const std::vector<CBlockHeader>& headers)\n+{\n+    // The caller should not give us an empty set of headers.\n+    Assume(headers.size() > 0);\n+    if (headers.size() == 0) return true;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    if (m_last_header_received.IsNull()) {\n+        m_last_header_received = m_chain_start->GetBlockHeader();\n+        m_current_height = m_chain_start->nHeight;\n+    }\n+\n+    if (headers[0].hashPrevBlock != m_last_header_received.GetHash()) {\n+        // Doesn't connect to what we expect\n+        Finalize();\n+        return false;\n+    }\n+\n+    // If it does connect, (minimally) validate and store a commitment to each one.\n+    for (const auto& hdr : headers) {\n+        if (!ValidateAndProcessSingleHeader(m_last_header_received, hdr, m_current_height+1)) {\n+            Finalize();\n+            return false;\n+        }\n+    }\n+\n+    if (m_current_chain_work >= m_minimum_required_work) {\n+        m_blockhash_with_sufficient_work = headers.back().GetHash();\n+        m_redownloaded_headers.clear();\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+        m_redownload_buffer_first_prev_hash = m_chain_start->GetBlockHash();\n+        m_redownload_buffer_last_hash.SetNull();\n+        m_download_state = State::REDOWNLOAD;\n+    }\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndProcessSingleHeader(const CBlockHeader& previous, const CBlockHeader& current, int64_t current_height)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Verify that the difficulty isn't growing too fast; an adversary with\n+    // limited hashing capability has a greater chance of producing a high\n+    // work chain if they compress the work into as few blocks as possible,\n+    // so don't let anyone give a chain that would violate the difficulty\n+    // adjustment maximum.\n+    if (!PermittedDifficultyTransition(m_consensus_params, current_height,\n+                previous.nBits, current.nBits)) {\n+        return false;\n+    }\n+\n+    if (!CheckProofOfWork(current.GetHash(), current.nBits, m_consensus_params)) return false;\n+\n+    if ((current_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+        // Try to add a commitment.\n+        m_header_commitments.push_back(m_hasher(current.GetHash()) & 1);\n+        if (m_header_commitments.size() > m_max_commitments) {\n+            // The peer's chain is too long; give up.\n+            // TODO: disconnect this peer.\n+            LogPrint(BCLog::NET, \"headers chain is too long; giving up sync peer=%d\\n\", m_id);\n+            return false;\n+        }\n+    }\n+\n+    m_current_chain_work += GetBlockProof(CBlockIndex(current));\n+    m_last_header_received = current;\n+    ++m_current_height;\n+\n+    return true;\n+}\n+\n+bool HeadersSyncState::ValidateAndStoreRedownloadedHeader(const CBlockHeader& header)\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return false;\n+\n+    // Ensure that we're working on a header that connects to the chain we're\n+    // downloading.\n+    if (m_redownloaded_headers.empty()) {\n+        if (header.hashPrevBlock != m_chain_start->GetBlockHash()) {\n+            return false;\n+        }\n+        m_redownload_buffer_last_height = m_chain_start->nHeight;\n+    } else if (header.hashPrevBlock != m_redownload_buffer_last_hash) {\n+        return false;\n+    }\n+\n+    int64_t next_height = m_redownload_buffer_last_height + 1;\n+\n+    // If we're at a header for which we previously stored a commitment, verify\n+    // it is correct. Failure will result in aborting download.\n+    if ((next_height - m_chain_start->nHeight) % HEADER_COMMITMENT_FREQUENCY == 0) {\n+         bool commitment = m_hasher(header.GetHash()) & 1;\n+         if (m_header_commitments.size() == 0) {\n+            // Somehow our peer managed to feed us a different chain and\n+            // we've run out of commitments.\n+            return false;\n+        }\n+        bool expected_commitment = m_header_commitments.front();\n+        m_header_commitments.pop_front();\n+        if (commitment != expected_commitment) {\n+            return false;\n+        }\n+    }\n+\n+    // Store this header for later processing.\n+    m_redownloaded_headers.push_back(header);\n+    m_redownload_buffer_last_height = next_height;\n+    m_redownload_buffer_last_hash = header.GetHash();\n+\n+    // If we're processing our target block header, which we verified has\n+    // sufficient work, then set a flag for processing all remaining headers.\n+    if (header.GetHash() == m_blockhash_with_sufficient_work) {\n+        m_process_all_remaining_headers = true;\n+    }\n+    return true;\n+}\n+\n+std::vector<CBlockHeader> HeadersSyncState::RemoveHeadersReadyForAcceptance()\n+{\n+    std::vector<CBlockHeader> ret;\n+\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return ret;\n+\n+    while (m_redownloaded_headers.size() > REDOWNLOAD_HEADERS_THRESHOLD ||\n+            (m_redownloaded_headers.size() > 0 && m_process_all_remaining_headers)) {\n+        ret.emplace_back(m_redownloaded_headers.front().GetFullHeader(m_redownload_buffer_first_prev_hash));\n+        m_redownloaded_headers.pop_front();\n+        m_redownload_buffer_first_prev_hash = ret.back().GetHash();\n+    }\n+    return ret;\n+}\n+\n+std::optional<CBlockLocator> HeadersSyncState::MakeNextHeadersRequest()\n+{\n+    Assume(m_download_state != State::FINAL);\n+    if (m_download_state == State::FINAL) return std::nullopt;\n+\n+    std::vector<uint256> locator;\n+\n+    if (m_download_state == State::INITIAL_DOWNLOAD && !m_last_header_received.IsNull()) {\n+        // During initial download, we continue from the last header received.\n+        locator.push_back(m_last_header_received.GetHash());\n+    }\n+\n+    if (m_download_state == State::REDOWNLOAD && !m_redownloaded_headers.empty()) {\n+        // During redownload, we will either download from the last received\n+        // header that we stored during the second download phase, or from the\n+        // fork point (m_chain_start).\n+        locator.push_back(m_redownload_buffer_last_hash);\n+    }\n+\n+    locator.insert(locator.end(), m_chain_start_locator.vHave.begin(),\n+            m_chain_start_locator.vHave.end());\n+    return CBlockLocator(locator);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932322801",
      "id" : 932322801,
      "line" : 317,
      "node_id" : "PRRC_kwDOABII5843kh3x",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 317,
      "original_position" : 317,
      "original_start_line" : null,
      "path" : "src/headerssync.cpp",
      "position" : 317,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932322801",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932330073"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073"
         }
      },
      "author_association" : "MEMBER",
      "body" : "In commit \"Utilize anti-DoS headers download strategy\"\r\n\r\nThis function really returns 3 things: an optional block locator, a vector of headers to process, and a bool processing_success. Having those spread over return values and mutable arguments is a bit ugly.\r\n\r\nHow about returning a typedef'd `std::optional<std::pair<std::optional<CBlockLocator>, std::vector<CBlockHeader>>>`, or making a simple custom struct to return the results in?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T14:50:56Z",
      "diff_hunk" : "@@ -0,0 +1,246 @@\n+// Copyright (c) 2022 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_HEADERSSYNC_H\n+#define BITCOIN_HEADERSSYNC_H\n+\n+#include <chain.h>\n+#include <primitives/block.h>\n+#include <uint256.h>\n+#include <arith_uint256.h>\n+#include <net.h> // For NodeId\n+#include <consensus/params.h>\n+#include <util/hasher.h>\n+#include <util/bitdeque.h>\n+\n+#include <vector>\n+#include <deque>\n+\n+// A compressed CBlockHeader, which leaves out the prevhash\n+struct CompressedHeader {\n+    // header\n+    int32_t nVersion{0};\n+    uint256 hashMerkleRoot;\n+    uint32_t nTime{0};\n+    uint32_t nBits{0};\n+    uint32_t nNonce{0};\n+\n+    CompressedHeader()\n+    {\n+        hashMerkleRoot.SetNull();\n+    }\n+\n+    CompressedHeader(const CBlockHeader& header)\n+    {\n+        nVersion = header.nVersion;\n+        hashMerkleRoot = header.hashMerkleRoot;\n+        nTime = header.nTime;\n+        nBits = header.nBits;\n+        nNonce = header.nNonce;\n+    }\n+\n+    CBlockHeader GetFullHeader(const uint256& hash_prev_block) {\n+        CBlockHeader ret;\n+        ret.nVersion = nVersion;\n+        ret.hashPrevBlock = hash_prev_block;\n+        ret.hashMerkleRoot = hashMerkleRoot;\n+        ret.nTime = nTime;\n+        ret.nBits = nBits;\n+        ret.nNonce = nNonce;\n+        return ret;\n+    };\n+};\n+\n+/** HeadersSyncState:\n+ *\n+ * We wish to download a peer's headers chain in a DoS-resistant way.\n+ *\n+ * The Bitcoin protocol does not offer an easy way to determine the work on a\n+ * peer's chain. Currently, we can query a peer's headers by using a GETHEADERS\n+ * message, and our peer can return a set of up to 2000 headers that connect to\n+ * something we know. If a peer's chain has more than 2000 blocks, then we need\n+ * a way to verify that the chain actually has enough work on it to be useful to\n+ * us -- by being above our anti-DoS minimum-chain-work threshold -- before we\n+ * commit to storing those headers in memory. Otherwise, it would be cheap for\n+ * an attacker to waste all our memory by serving us low-work headers\n+ * (particularly for a new node coming online for the first time).\n+ *\n+ * To prevent memory-DoS with low-work headers, while still always being\n+ * able to reorg to whatever the most-work chain is, we require that a chain\n+ * meet a work threshold before committing it to memory. We can do this by\n+ * downloading a peer's headers twice, whenever we are not sure that the chain\n+ * has sufficient work:\n+ *\n+ * - In the first download phase, we can calculate the work on the chain as we\n+ * go (just by checking the nBits value on each header, and validating the\n+ * proof-of-work).\n+ *\n+ * - Once we have reached a header where the cumulative chain work is\n+ * sufficient, we switch to downloading the headers a second time, this time\n+ * storing them in memory.\n+ *\n+ * To prevent an attacker from using (eg) the honest chain to convince us that\n+ * they have a high-work chain, but then feeding us an alternate set of\n+ * low-difficulty headers in the second phase, we store commitments to the\n+ * chain we see in the first download phase that we check in the second phase,\n+ * as follows:\n+ *\n+ * - In phase 1, store 1 bit (using a salted hash function) for every N headers\n+ * that we see. With a reasonable choice of N, this uses relatively little\n+ * memory even for a very long chain.\n+ *\n+ * - In phase 2 (redownload), keep a lookahead buffer of size H, and only\n+ * accept a batch of N (N < H) headers to memory once we've verified that H/N =\n+ * S commitments have all passed verification. With this parametrization, we\n+ * can achieve a given security target (S) while choosing H and N to minimize\n+ * memory usage in this scheme.\n+ */\n+\n+class HeadersSyncState {\n+public:\n+    HeadersSyncState(NodeId id, const Consensus::Params& consensus_params);\n+    ~HeadersSyncState() {}\n+\n+    enum class State {\n+        /** INITIAL_DOWNLOAD means the peer has not yet demonstrated their\n+         * chain has sufficient work */\n+        INITIAL_DOWNLOAD,\n+        /** REDOWNLOAD means the peer has given us a high-enough-work chain,\n+         * and now we're redownloading the headers we saw before and trying to\n+         * accept them */\n+        REDOWNLOAD,\n+        /** We're done syncing with this peer and can discard any remaining state */\n+        FINAL\n+    };\n+\n+    /** Return the current state of our download */\n+    State GetState() const { return m_download_state; }\n+\n+    /** Start headers sync (via this download-twice mechanism)\n+     * chain_start: best known fork point that the peer's headers branch from\n+     * initial_headers: first batch of headers to process\n+     * minimum_required_work: amount of chain work required to accept the chain\n+     */\n+    std::optional<CBlockLocator> StartInitialDownload(const CBlockIndex* chain_start, const\n+            std::vector<CBlockHeader>& initial_headers, const arith_uint256&\n+            minimum_required_work, CBlockLocator&& chain_start_locator);\n+\n+    /** Process a batch of headers, once a sync via this mechanism has started\n+     *\n+     * headers: headers that were received over the network for processing\n+     * full_headers_message: true if the message was at max capacity,\n+     *                       indicating more headers may be available\n+     * headers_to_process: will be filled in with any headers that the caller\n+     *                     can process and validate now (because these returned\n+     *                     headers are on a chain with sufficient work)\n+     * processing_success: set to false if an error is detected and the sync is\n+     *                     aborted; true otherwise.\n+     */\n+    std::optional<CBlockLocator> ProcessNextHeaders(const std::vector<CBlockHeader>& headers,",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932330073",
      "id" : 932330073,
      "line" : 140,
      "node_id" : "PRRC_kwDOABII5843kjpZ",
      "original_commit_id" : "de72d0867dbcbab6e2f68a73c48e99497c5efd7a",
      "original_line" : 140,
      "original_position" : 140,
      "original_start_line" : null,
      "path" : "src/headerssync.h",
      "position" : 140,
      "pull_request_review_id" : 1054116591,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T14:52:01Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932330073",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   },
   {
      "author_association" : "MEMBER",
      "body" : "concept ACK, cool to see such an old idea actually get implemented",
      "created_at" : "2022-07-28T18:22:55Z",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#issuecomment-1198490639",
      "id" : 1198490639,
      "issue_url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/25717",
      "node_id" : "IC_kwDOABII585Hb4QP",
      "performed_via_github_app" : null,
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1198490639/reactions"
      },
      "updated_at" : "2022-07-28T18:22:55Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/1198490639",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932560137"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this relation between `pindexLast.nBits` and `expected_nbits` be explicitly computed? Would make the test condition below abundantly clear.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:38:44Z",
      "diff_hunk" : "@@ -44,7 +48,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_lower_limit_actual)\n     pindexLast.nHeight = 68543;\n     pindexLast.nTime = 1279297671;  // Block #68543\n     pindexLast.nBits = 0x1c05a3f4;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1c0168fdU);\n+    unsigned int expected_nbits = 0x1c0168fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932560137",
      "id" : 932560137,
      "line" : 51,
      "node_id" : "PRRC_kwDOABII5843lb0J",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 51,
      "original_position" : 27,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 27,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932560137",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562089"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this just be the (casted) value of pindexLast.nBits?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:41:12Z",
      "diff_hunk" : "@@ -32,7 +34,9 @@ BOOST_AUTO_TEST_CASE(get_next_work_pow_limit)\n     pindexLast.nHeight = 2015;\n     pindexLast.nTime = 1233061996;  // Block #2015\n     pindexLast.nBits = 0x1d00ffff;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1d00ffffU);\n+    unsigned int expected_nbits = 0x1d00ffffU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562089",
      "id" : 932562089,
      "line" : 37,
      "node_id" : "PRRC_kwDOABII5843lcSp",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 37,
      "original_position" : 16,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 16,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562089",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562835"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835"
         }
      },
      "author_association" : "MEMBER",
      "body" : "can this relation between `pindexLast.nBits` and `expected_nbits` be explicitly computed? Would make the test condition below abundantly clear.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:42:06Z",
      "diff_hunk" : "@@ -56,7 +65,12 @@ BOOST_AUTO_TEST_CASE(get_next_work_upper_limit_actual)\n     pindexLast.nHeight = 46367;\n     pindexLast.nTime = 1269211443;  // Block #46367\n     pindexLast.nBits = 0x1c387f6f;\n-    BOOST_CHECK_EQUAL(CalculateNextWorkRequired(&pindexLast, nLastRetargetTime, chainParams->GetConsensus()), 0x1d00e1fdU);\n+    unsigned int expected_nbits = 0x1d00e1fdU;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932562835",
      "id" : 932562835,
      "line" : 68,
      "node_id" : "PRRC_kwDOABII5843lceT",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 68,
      "original_position" : 41,
      "original_start_line" : null,
      "path" : "src/test/pow_tests.cpp",
      "position" : 41,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932562835",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932564292"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292"
         }
      },
      "author_association" : "MEMBER",
      "body" : "while we're here, what does `bn` actually refer to? :grimacing: \r\n\r\nwouldn't mind tossing the old naming schemes for this",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:44:03Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;\n+\n+    if (height % params.DifficultyAdjustmentInterval() == 0) {\n+        int64_t smallest_timespan = params.nPowTargetTimespan/4;\n+        int64_t largest_timespan = params.nPowTargetTimespan*4;\n+\n+        const arith_uint256 bnPowLimit = UintToArith256(params.powLimit);",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932564292",
      "id" : 932564292,
      "line" : 84,
      "node_id" : "PRRC_kwDOABII5843lc1E",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 84,
      "original_position" : 14,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 14,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932564292",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932566102"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102"
         }
      },
      "author_association" : "MEMBER",
      "body" : "splitting hairs maybe but should this also check new_bits is at/above powLimit?",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T18:46:19Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932566102",
      "id" : 932566102,
      "line" : 78,
      "node_id" : "PRRC_kwDOABII5843ldRW",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 78,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 8,
      "pull_request_review_id" : 1054584671,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T18:50:21Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932566102",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/5767891?v=4",
         "events_url" : "https://api.github.com/users/instagibbs/events{/privacy}",
         "followers_url" : "https://api.github.com/users/instagibbs/followers",
         "following_url" : "https://api.github.com/users/instagibbs/following{/other_user}",
         "gists_url" : "https://api.github.com/users/instagibbs/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/instagibbs",
         "id" : 5767891,
         "login" : "instagibbs",
         "node_id" : "MDQ6VXNlcjU3Njc4OTE=",
         "organizations_url" : "https://api.github.com/users/instagibbs/orgs",
         "received_events_url" : "https://api.github.com/users/instagibbs/received_events",
         "repos_url" : "https://api.github.com/users/instagibbs/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/instagibbs/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/instagibbs/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/instagibbs"
      }
   },
   {
      "_links" : {
         "html" : {
            "href" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932604102"
         },
         "pull_request" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717"
         },
         "self" : {
            "href" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102"
         }
      },
      "author_association" : "MEMBER",
      "body" : "For the purposes of what is needed for the security analysis of the overall header commitment scheme, the only requirements are that this verifies (a) that the difficulty doesn't change on non-2016-multiple blocks and (b) doesn't go up or down too quickly. Its goal is forcing the attacker to spread out their attempted PoW over many blocks, rather than just one or a few (because creating `N` blocks with each difficulty `D` is much harder than creating one block with difficulty `N*D`, if the hashpower available to the attacker is less than the expected value for an `N*D` difficulty block).\r\n\r\nNo objection to checking whatever can be checked with the provided arguments, but I think the current code just chooses to check exactly what is needed, and document it, rather than verify everything possible.",
      "commit_id" : "7bed25cbd3776189d47f3771ab3abc180ff34077",
      "created_at" : "2022-07-28T19:37:05Z",
      "diff_hunk" : "@@ -71,6 +71,54 @@ unsigned int CalculateNextWorkRequired(const CBlockIndex* pindexLast, int64_t nF\n     return bnNew.GetCompact();\n }\n \n+// Check that on difficulty adjustments, the new difficulty does not increase\n+// or decrease beyond the permitted limits.\n+bool PermittedDifficultyTransition(const Consensus::Params& params, int64_t height, uint32_t old_nbits, uint32_t new_nbits)\n+{\n+    if (params.fPowAllowMinDifficultyBlocks) return true;",
      "html_url" : "https://github.com/bitcoin/bitcoin/pull/25717#discussion_r932604102",
      "id" : 932604102,
      "in_reply_to_id" : 932566102,
      "line" : 78,
      "node_id" : "PRRC_kwDOABII5843lmjG",
      "original_commit_id" : "cbf3069c7d76888a647d68dbb09d77e666dcaf50",
      "original_line" : 78,
      "original_position" : 8,
      "original_start_line" : null,
      "path" : "src/pow.cpp",
      "position" : 8,
      "pull_request_review_id" : 1054648121,
      "pull_request_url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/25717",
      "reactions" : {
         "+1" : 0,
         "-1" : 0,
         "confused" : 0,
         "eyes" : 0,
         "heart" : 0,
         "hooray" : 0,
         "laugh" : 0,
         "rocket" : 0,
         "total_count" : 0,
         "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102/reactions"
      },
      "side" : "RIGHT",
      "start_line" : null,
      "start_side" : null,
      "updated_at" : "2022-07-28T19:39:47Z",
      "url" : "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/932604102",
      "user" : {
         "avatar_url" : "https://avatars.githubusercontent.com/u/548488?v=4",
         "events_url" : "https://api.github.com/users/sipa/events{/privacy}",
         "followers_url" : "https://api.github.com/users/sipa/followers",
         "following_url" : "https://api.github.com/users/sipa/following{/other_user}",
         "gists_url" : "https://api.github.com/users/sipa/gists{/gist_id}",
         "gravatar_id" : "",
         "html_url" : "https://github.com/sipa",
         "id" : 548488,
         "login" : "sipa",
         "node_id" : "MDQ6VXNlcjU0ODQ4OA==",
         "organizations_url" : "https://api.github.com/users/sipa/orgs",
         "received_events_url" : "https://api.github.com/users/sipa/received_events",
         "repos_url" : "https://api.github.com/users/sipa/repos",
         "site_admin" : false,
         "starred_url" : "https://api.github.com/users/sipa/starred{/owner}{/repo}",
         "subscriptions_url" : "https://api.github.com/users/sipa/subscriptions",
         "type" : "User",
         "url" : "https://api.github.com/users/sipa"
      }
   }
]
